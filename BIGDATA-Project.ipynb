{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce715a02",
   "metadata": {},
   "source": [
    "__AUTHORS__:\n",
    "  - Théo Perinet (22172 - theo.perinet)\n",
    "  - Mathieu Rivier (23553 - mathieu.rivier)\n",
    "  - Marc Monteil (23742 - marc.monteil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6dca563",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#BigData---Final-Project\" data-toc-modified-id=\"BigData---Final-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>BigData - Final Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-The-Data\" data-toc-modified-id=\"Loading-The-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loading The Data</a></span></li><li><span><a href=\"#Exploring-The-Data\" data-toc-modified-id=\"Exploring-The-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Exploring The Data</a></span></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Analysis</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d16f4d",
   "metadata": {},
   "source": [
    "# BigData - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38335eff",
   "metadata": {},
   "source": [
    "###### To Use when you are on google collab\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz  \n",
    "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea659e8b",
   "metadata": {},
   "source": [
    "###### TO USE WHEN YOU ARE ON GOOGLE COLLAB\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80976068",
   "metadata": {},
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8e3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_application_name = \"WannaFlop_Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8bad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/SPARK/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/20 09:35:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(spark_application_name).getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0926b5",
   "metadata": {},
   "source": [
    "## Exploring The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f2f390ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType, StructType,StructField\n",
    "from pyspark.sql.functions import desc\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b56d2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class read_info(object):\n",
    "    def __init__(self, file_path, header=False, delimiter=';', schema=None):\n",
    "        self.file_path = file_path\n",
    "        self.header = header\n",
    "        self.delimiter = delimiter\n",
    "        self.schema = schema\n",
    "\n",
    "        self.df = self._load_df()\n",
    "\n",
    "        #self.df_abstract = self._get_df_abstract()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self._nb_rows()} \\n{self.df.printSchema()} \\n{self.get_df_abstract()}\\n {self.show_missing()}\\n{self._get_stats()}\"\n",
    "\n",
    "    def show_missing(self):\n",
    "        print(\"Missing Data per column:\")\n",
    "        self._count_missing().show()\n",
    "\n",
    "    def _get_num_cols(self):\n",
    "        num_cols = [\n",
    "            f.name for f in self.df.schema.fields\n",
    "            if isinstance(f.dataType, DoubleType) or\n",
    "            isinstance(f.dataType, IntegerType)\n",
    "        ]\n",
    "        \n",
    "        return num_cols\n",
    "    def _get_rounded_df(self):\n",
    "        rounded_df = self.df\n",
    "        dbl_cols = self._get_num_cols()\n",
    "        for col in dbl_cols:\n",
    "            rounded_df = rounded_df.withColumn(col, func.round('high'))\n",
    "\n",
    "        return rounded_df\n",
    "\n",
    "    def get_df_abstract(self):\n",
    "        rounded_df = self._get_rounded_df()\n",
    "\n",
    "        # First 40 rows\n",
    "        print(\"First 40 rows:\")\n",
    "        rounded_df.show(40)\n",
    "\n",
    "        # Last 40 rows\n",
    "        print(\"Last 40 rows:\")\n",
    "        rounded_df = rounded_df.withColumn(\n",
    "            \"index\", monotonically_increasing_id()\n",
    "        )\n",
    "        rounded_df.orderBy(desc(\"index\")).drop(\"index\").show(40)\n",
    "\n",
    "    def _get_periodicity(self):\n",
    "        self.df['data'][0]\n",
    "\n",
    "    def _nb_rows(self):\n",
    "        # Number of total rows\n",
    "        print(\"Number of rows: \" + str(self.df.count()) + \"\\n\")\n",
    "\n",
    "    def _handle_csv(self):\n",
    "        '''\n",
    "        @description: Read the csv file and return a Spark DataFrame\n",
    "\n",
    "        @arg csv_file_path: Path to the csv file\n",
    "        @arg header: boolean whether to load a header or not\n",
    "        @arg delimiter: which delimiter to use by default\n",
    "        '''\n",
    "        return spark.read.option(\"inferSchema\", \"true\").option(\"nullValue\", \"null\").csv(\n",
    "            self.file_path,\n",
    "            sep=self.delimiter,\n",
    "            schema=self.schema,\n",
    "            header=self.header,\n",
    "        )\n",
    "    \n",
    "    def _handle_json(self):\n",
    "        return spark.read.json(self.file_path)\n",
    "\n",
    "    def _load_df(self):\n",
    "        ####### ADD TRY CATCH #####\n",
    "        extension = self.file_path.split(\".\")[-1]\n",
    "\n",
    "        df = None\n",
    "        if extension == 'json':\n",
    "            df = self._handle_json()\n",
    "        elif extension == 'csv':\n",
    "            df = self._handle_csv()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _count_missing(self):\n",
    "        cols = self.df.columns\n",
    "        cols.remove('Date')\n",
    "        return self.df.select(\n",
    "            [\n",
    "                count(when(isnan(c) | col(c).isNull(), c)).alias(c)\n",
    "                for c in cols\n",
    "            ]\n",
    "        )\n",
    "        #.show()\n",
    "        \n",
    "    def _get_stats(self):\n",
    "        self.df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "ddc708b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mh\u001b[49m)\n\u001b[1;32m      2\u001b[0m h\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(h)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "print(h)\n",
    "h.remove('Date')\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3309520c",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_schema = StructType([\n",
    "    StructField('Date', DateType(), True),\n",
    "    StructField('High', DoubleType(), True),\n",
    "    StructField('Low', DoubleType(), True),\n",
    "    StructField('Open', DoubleType(), True),\n",
    "    StructField('Close', DoubleType(), True),\n",
    "    StructField('Volume', IntegerType(), True),\n",
    "    StructField('Adj Close', DoubleType(), True),\n",
    "    StructField('company_name', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "276a609a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m AMZN \u001b[38;5;241m=\u001b[39m \u001b[43mread_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstocks_data/AMAZON.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamzn_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mread_info.__init__\u001b[0;34m(self, file_path, header, delimiter, schema)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter \u001b[38;5;241m=\u001b[39m delimiter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m schema\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mread_info._load_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_json()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 82\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mread_info._handle_csv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_csv\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    @description: Read the csv file and return a Spark DataFrame\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    @arg delimiter: which delimiter to use by default\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnullValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path,\n\u001b[1;32m     66\u001b[0m         sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter,\n\u001b[1;32m     67\u001b[0m         schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema,\n\u001b[1;32m     68\u001b[0m         header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader,\n\u001b[1;32m     69\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "AMZN = read_info('stocks_data/AMAZON.csv', header=True, delimiter=',', schema=amzn_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05cbf75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stock_info.Stock object at 0x11330e3a0>\n"
     ]
    }
   ],
   "source": [
    "print(AMZN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39f70176",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### A FAIRE !!!! UN SCHEMA !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5f20d96c",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stock' object has no attribute 'get_df_abstract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_df_abstract\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stock' object has no attribute 'get_df_abstract'"
     ]
    }
   ],
   "source": [
    "AMZN.get_df_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82df148b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stock' object has no attribute 'show_missing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_missing\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stock' object has no attribute 'show_missing'"
     ]
    }
   ],
   "source": [
    "AMZN.show_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "0ade05c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stock' object has no attribute '_get_stats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_stats\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stock' object has no attribute '_get_stats'"
     ]
    }
   ],
   "source": [
    "AMZN._get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2082b19e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Can't extract value from date#4536: need struct type but got date",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatediff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2478\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Can't extract value from date#4536: need struct type but got date"
     ]
    }
   ],
   "source": [
    "AMZN.df.withColumn(\"test\", \n",
    "              func.datediff(AMZN.df[\"date\"][0], AMZN.df[\"date\"][1])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "2471b4ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Date[2]'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df[\"Date\"].getItem(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "c5a729b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 1, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df.first()['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "3bf431bf",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '__get_item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_item\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '__get_item'"
     ]
    }
   ],
   "source": [
    "AMZN.df.__get_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ec237649",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'second'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecond\u001b[49m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'second'"
     ]
    }
   ],
   "source": [
    "AMZN.df.second()['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "19a0206f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspark.sql.functions' has no attribute 'getrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetrows\u001b[49m(AMZN\u001b[38;5;241m.\u001b[39mdf, rownums\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyspark.sql.functions' has no attribute 'getrows'"
     ]
    }
   ],
   "source": [
    "func.getrows(AMZN.df, rownums=[0, 2]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa9e290",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df[0].__getitem__(\"Date\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adc0d321",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde60b2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.select('Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82c16ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d130cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "\n",
    "my_window = Window.partitionBy().orderBy(\"Date\")\n",
    "\n",
    "df = AMZN.df.withColumn(\"prev_value\", F.lag(AMZN.df.Date).over(my_window))\n",
    "df = df.withColumn(\"diff\", F.when(F.isnull(F.datediff(df.Date, df.prev_value)), 0)\n",
    "                              .otherwise(F.datediff(df.Date, df.prev_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb18e01a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"diff\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a4eefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7fca05",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(mean('diff')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6425cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.stat.corr('High', 'Low')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b908337",
   "metadata": {},
   "source": [
    "TODO: Create function to compute per month week year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e9aa407",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.select(mean (\"Close\")).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18877ae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_mean(df, col):\n",
    "    return df.select(mean (col)).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6f0ba08",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_col_mean(AMZN.df, \"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b901b1a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.weekofyear(\"day\").alias(\"date_by_week\")).agg(sum(\"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57227040",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.weekofyear(\"day\").alias(\"date_by_week\")).agg(sum(\"Close\")).orderBy(\"date_by_week\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d626b65f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.withColumn(\"Date\",func.date_sub(func.next_day(col(\"Date\"),\"sunday\"),7)).groupBy(\"Date\").agg(sum(\"Close\").cast(\"int\").alias(\"Close_total\")).orderBy(\"week_strt_day\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bec6acb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(\"Date\").select(\"Close\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0ab75e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.month(\"Date\").alias(\"hour\")).agg(mean(\"Close\").alias(\"close_mean\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a9fee92",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.year(\"Date\").alias(\"hour\")).agg(mean(\"Close\").alias(\"close_mean\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81410bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "657c514e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_avg(AMZN.df, \"Close\", func.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe7a904e",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_avg(AMZN.df, \"Open\", func.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d1a885",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exploration(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def get_oc_avg(self, fun):\n",
    "        close = self._compute_avg(self.df, \"Close\", fun)\n",
    "        opening = self._compute_avg(self.df, \"Open\", fun)\n",
    "\n",
    "        return close.join(\n",
    "            opening, opening.Open_new_time == close.Close_new_time, \"inner\"\n",
    "        ).orderBy(\"Close_new_time\").select(\n",
    "            close.Close_new_time, close.Close_mean, opening.Open_mean\n",
    "        )\n",
    "\n",
    "    def _compute_avg(self, df, col, fun):\n",
    "        return df.groupBy(fun(\"Date\").alias(col + \"_new_time\")).agg(\n",
    "            mean(col).alias(col + \"_mean\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90f0b4a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "exAMZN = Exploration(AMZN.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "babb45bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "exAMZN.get_oc_avg(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a65a33f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "exAMZN.get_oc_avg(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4be3f230",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_change(period=None):\n",
    "    df = AMZN.df\n",
    "    if period:\n",
    "        df= exAMZN.get_oc_avg(period)\n",
    "   \n",
    "    return  df.withColumn('diff', ( df['Close_mean'] - df['Open_mean'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d621c69",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price_change(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eceae3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price_change(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2422fc84",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150918b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47242790",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "412c45ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "93323324",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/SPARK/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/20 15:34:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "from stock_info import Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8bac1cc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType, StructType,StructField"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "bb14e26d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_schema = StructType([\n",
    "    StructField('Date', DateType(), True),\n",
    "    StructField('High', DoubleType(), True),\n",
    "    StructField('Low', DoubleType(), True),\n",
    "    StructField('Open', DoubleType(), True),\n",
    "    StructField('Close', DoubleType(), True),\n",
    "    StructField('Volume', IntegerType(), True),\n",
    "    StructField('Adj Close', DoubleType(), True),\n",
    "    StructField('company_name', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "64cdc75f",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN = Stock('stocks_data/MICROSOFT.csv', header=True, delimiter=',', schema=amzn_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5e481a0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      "\n",
      "First 40 rows:\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|      Date|High| Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|2017-01-03|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-04|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-05|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-06|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-09|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-10|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-11|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-12|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-13|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-17|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-18|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-19|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-20|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-23|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-24|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-25|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-26|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-01-27|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-30|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-31|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-02|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-02-03|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-06|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-07|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-08|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-09|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-10|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-13|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-14|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-15|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-16|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-17|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-21|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-22|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-23|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-24|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-27|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-28|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-03-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Last 40 rows:\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|      Date| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|2020-12-02|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-12-01|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-30|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-27|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-11-25|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-24|214.0|214.0|214.0|214.0| 214.0|    214.0|   MICROSOFT|\n",
      "|2020-11-23|212.0|212.0|212.0|212.0| 212.0|    212.0|   MICROSOFT|\n",
      "|2020-11-20|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-19|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-18|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-17|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-16|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-13|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-12|219.0|219.0|219.0|219.0| 219.0|    219.0|   MICROSOFT|\n",
      "|2020-11-11|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-10|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-09|228.0|228.0|228.0|228.0| 228.0|    228.0|   MICROSOFT|\n",
      "|2020-11-06|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-05|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-04|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-03|208.0|208.0|208.0|208.0| 208.0|    208.0|   MICROSOFT|\n",
      "|2020-11-02|205.0|205.0|205.0|205.0| 205.0|    205.0|   MICROSOFT|\n",
      "|2020-10-30|204.0|204.0|204.0|204.0| 204.0|    204.0|   MICROSOFT|\n",
      "|2020-10-29|207.0|207.0|207.0|207.0| 207.0|    207.0|   MICROSOFT|\n",
      "|2020-10-28|209.0|209.0|209.0|209.0| 209.0|    209.0|   MICROSOFT|\n",
      "|2020-10-27|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-10-26|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-23|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-22|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-21|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-20|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-19|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-16|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-15|220.0|220.0|220.0|220.0| 220.0|    220.0|   MICROSOFT|\n",
      "|2020-10-14|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-13|225.0|225.0|225.0|225.0| 225.0|    225.0|   MICROSOFT|\n",
      "|2020-10-12|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-09|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-08|211.0|211.0|211.0|211.0| 211.0|    211.0|   MICROSOFT|\n",
      "|2020-10-07|210.0|210.0|210.0|210.0| 210.0|    210.0|   MICROSOFT|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Number of rows: 987\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Stats:\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|summary| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|  count|987.0|987.0|987.0|987.0| 987.0|    987.0|         987|\n",
      "|   mean|124.0|124.0|124.0|124.0| 124.0|    124.0|        null|\n",
      "| stddev| 46.0| 46.0| 46.0| 46.0|  46.0|     46.0|        null|\n",
      "|    min| 63.0| 63.0| 63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|    25%| 86.0| 86.0| 86.0| 86.0|  86.0|     86.0|        null|\n",
      "|    50%|111.0|111.0|111.0|111.0| 111.0|    111.0|        null|\n",
      "|    75%|152.0|152.0|152.0|152.0| 152.0|    152.0|        null|\n",
      "|    max|233.0|233.0|233.0|233.0| 233.0|    233.0|   MICROSOFT|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "\n",
      "Missing Data per column:\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|High|Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|   0|  0|   0|    0|   987|        0|           0|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "            None\n",
       "\n",
       "            None\n",
       "\n",
       "            None\n",
       "\n",
       "            None\n",
       "\n",
       "            None"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e67992cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore._nb_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dfb20805",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore._print_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "86e42473",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 40 rows:\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|      Date|High| Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|2017-01-03|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-04|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-05|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-06|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-09|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-10|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-11|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-12|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-13|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-17|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-18|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-19|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-20|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-23|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-24|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-25|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-26|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-01-27|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-30|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-31|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-02|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-02-03|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-06|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-07|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-08|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-09|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-10|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-13|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-14|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-15|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-16|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-17|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-21|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-22|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-23|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-24|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-27|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-28|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-03-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Last 40 rows:\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|      Date| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|2020-12-02|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-12-01|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-30|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-27|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-11-25|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-24|214.0|214.0|214.0|214.0| 214.0|    214.0|   MICROSOFT|\n",
      "|2020-11-23|212.0|212.0|212.0|212.0| 212.0|    212.0|   MICROSOFT|\n",
      "|2020-11-20|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-19|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-18|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-17|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-16|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-13|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-12|219.0|219.0|219.0|219.0| 219.0|    219.0|   MICROSOFT|\n",
      "|2020-11-11|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-10|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-09|228.0|228.0|228.0|228.0| 228.0|    228.0|   MICROSOFT|\n",
      "|2020-11-06|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-05|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-04|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-03|208.0|208.0|208.0|208.0| 208.0|    208.0|   MICROSOFT|\n",
      "|2020-11-02|205.0|205.0|205.0|205.0| 205.0|    205.0|   MICROSOFT|\n",
      "|2020-10-30|204.0|204.0|204.0|204.0| 204.0|    204.0|   MICROSOFT|\n",
      "|2020-10-29|207.0|207.0|207.0|207.0| 207.0|    207.0|   MICROSOFT|\n",
      "|2020-10-28|209.0|209.0|209.0|209.0| 209.0|    209.0|   MICROSOFT|\n",
      "|2020-10-27|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-10-26|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-23|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-22|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-21|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-20|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-19|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-16|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-15|220.0|220.0|220.0|220.0| 220.0|    220.0|   MICROSOFT|\n",
      "|2020-10-14|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-13|225.0|225.0|225.0|225.0| 225.0|    225.0|   MICROSOFT|\n",
      "|2020-10-12|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-09|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-08|211.0|211.0|211.0|211.0| 211.0|    211.0|   MICROSOFT|\n",
      "|2020-10-07|210.0|210.0|210.0|210.0| 210.0|    210.0|   MICROSOFT|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore.get_df_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b32eacf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data per column:\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|High|Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|   0|  0|   0|    0|   987|        0|           0|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore.get_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "6161f25c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Stats:\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|summary| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|  count|987.0|987.0|987.0|987.0| 987.0|    987.0|         987|\n",
      "|   mean|124.0|124.0|124.0|124.0| 124.0|    124.0|        null|\n",
      "| stddev| 46.0| 46.0| 46.0| 46.0|  46.0|     46.0|        null|\n",
      "|    min| 63.0| 63.0| 63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|    25%| 86.0| 86.0| 86.0| 86.0|  86.0|     86.0|        null|\n",
      "|    50%|111.0|111.0|111.0|111.0| 111.0|    111.0|        null|\n",
      "|    75%|152.0|152.0|152.0|152.0| 152.0|    152.0|        null|\n",
      "|    max|233.0|233.0|233.0|233.0| 233.0|    233.0|   MICROSOFT|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3db42792",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8f3f5a08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+\n",
      "|   Date|        Close_mean|         Open_mean|\n",
      "+-------+------------------+------------------+\n",
      "|2017-01| 63.19199962615967|63.185500144958496|\n",
      "|2017-02| 64.11368440326892| 64.13473711515728|\n",
      "|2017-03| 64.84130494490914| 64.76434906669284|\n",
      "|2017-04| 66.17157946134868| 66.23894781815379|\n",
      "|2017-05| 68.91727308793502| 68.82818222045898|\n",
      "|2017-06|  70.5181815407493| 70.56181820956144|\n",
      "|2017-07| 72.01050033569337| 71.84349975585937|\n",
      "|2017-08| 72.81695755668308|  72.7156518023947|\n",
      "|2017-09| 74.34450073242188|  74.3654998779297|\n",
      "|2017-10| 77.93954571810636| 77.89318119395863|\n",
      "|2017-11| 83.71761903308686| 83.64523824055989|\n",
      "|2017-12|   84.758500289917| 84.83599967956543|\n",
      "|2018-01| 90.07523781912667| 89.96666681198846|\n",
      "|2018-02| 91.36789462440892| 91.43736829255757|\n",
      "|2018-03| 92.89904748825799| 93.23047601609002|\n",
      "|2018-04| 93.21476164318267| 93.53095318022228|\n",
      "|2018-05| 96.98136381669478| 96.63272718949752|\n",
      "|2018-06|100.56190454392205|100.66571517217727|\n",
      "|2018-07| 104.6385730561756|104.58571479434059|\n",
      "|2018-08|108.68434740149456|108.45391281791355|\n",
      "+-------+------------------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_oc_avg(\"month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "154aeea6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+\n",
      "|Date|        Close_mean|         Open_mean|\n",
      "+----+------------------+------------------+\n",
      "|2017| 71.98402421502954| 71.95430287516925|\n",
      "|2018|101.03398411967365|101.12235092831799|\n",
      "|2019|130.38202400813026|130.33904787093874|\n",
      "|2020| 190.8616180419922|190.76480678836674|\n",
      "+----+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_oc_avg(\"year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bf1ccf22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+\n",
      "|   Date|        Close_mean|         Open_mean|                diff|\n",
      "+-------+------------------+------------------+--------------------+\n",
      "|2017-01| 63.19199962615967|63.185500144958496|0.006499481201174717|\n",
      "|2017-02| 64.11368440326892| 64.13473711515728|  -0.021052711888359|\n",
      "|2017-03| 64.84130494490914| 64.76434906669284| 0.07695587821629601|\n",
      "|2017-04| 66.17157946134868| 66.23894781815379|-0.06736835680510467|\n",
      "|2017-05| 68.91727308793502| 68.82818222045898| 0.08909086747603112|\n",
      "|2017-06|  70.5181815407493| 70.56181820956144|-0.04363666881214101|\n",
      "|2017-07| 72.01050033569337| 71.84349975585937| 0.16700057983399574|\n",
      "|2017-08| 72.81695755668308|  72.7156518023947| 0.10130575428837574|\n",
      "|2017-09| 74.34450073242188|  74.3654998779297|-0.02099914550781...|\n",
      "|2017-10| 77.93954571810636| 77.89318119395863| 0.04636452414773373|\n",
      "|2017-11| 83.71761903308686| 83.64523824055989| 0.07238079252697105|\n",
      "|2017-12|   84.758500289917| 84.83599967956543| -0.0774993896484375|\n",
      "|2018-01| 90.07523781912667| 89.96666681198846| 0.10857100713820955|\n",
      "|2018-02| 91.36789462440892| 91.43736829255757|-0.06947366814864608|\n",
      "|2018-03| 92.89904748825799| 93.23047601609002|-0.33142852783203125|\n",
      "|2018-04| 93.21476164318267| 93.53095318022228|-0.31619153703961445|\n",
      "|2018-05| 96.98136381669478| 96.63272718949752|  0.3486366271972656|\n",
      "|2018-06|100.56190454392205|100.66571517217727|-0.10381062825521781|\n",
      "|2018-07| 104.6385730561756|104.58571479434059|0.052858261835012854|\n",
      "|2018-08|108.68434740149456|108.45391281791355| 0.23043458358101532|\n",
      "+-------+------------------+------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_price_change(\"month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "82b860ab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+--------------------+\n",
      "|Date|        Close_mean|         Open_mean|                diff|\n",
      "+----+------------------+------------------+--------------------+\n",
      "|2017| 71.98402421502954| 71.95430287516925|  0.0297213398602878|\n",
      "|2018|101.03398411967365|101.12235092831799|-0.08836680864433788|\n",
      "|2019|130.38202400813026|130.33904787093874| 0.04297613719151627|\n",
      "|2020| 190.8616180419922|190.76480678836674| 0.09681125362544662|\n",
      "+----+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_price_change(\"year\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c108afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "(AMZN.df.withColumn('Date', func.date_format(func.col('Date'), 'yyyy-MM'))\n",
    ".groupBy('Date')\n",
    ".agg(func.mean('Close'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cc230d44",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   Date|        Close_mean|\n",
      "+-------+------------------+\n",
      "|2017-01| 63.19199962615967|\n",
      "|2017-02| 64.11368440326892|\n",
      "|2017-03| 64.84130494490914|\n",
      "|2017-04| 66.17157946134868|\n",
      "|2017-05| 68.91727308793502|\n",
      "|2017-06|  70.5181815407493|\n",
      "|2017-07| 72.01050033569337|\n",
      "|2017-08| 72.81695755668308|\n",
      "|2017-09| 74.34450073242188|\n",
      "|2017-10| 77.93954571810636|\n",
      "|2017-11| 83.71761903308686|\n",
      "|2017-12|   84.758500289917|\n",
      "|2018-01| 90.07523781912667|\n",
      "|2018-02| 91.36789462440892|\n",
      "|2018-03| 92.89904748825799|\n",
      "|2018-04| 93.21476164318267|\n",
      "|2018-05| 96.98136381669478|\n",
      "|2018-06|100.56190454392205|\n",
      "|2018-07| 104.6385730561756|\n",
      "|2018-08|108.68434740149456|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis._compute_avg(AMZN.df, \"Close\", \"month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84d2b4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a7c86f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+--------------------+--------------------+\n",
      "|   Date|        Close_mean|         Open_mean|                diff|             daily_r|\n",
      "+-------+------------------+------------------+--------------------+--------------------+\n",
      "|2017-01| 63.19199962615967|63.185500144958496|0.006499481201174717|0.042204423384251406|\n",
      "|2017-02| 64.11368440326892| 64.13473711515728|  -0.021052711888359|-0.13670592135298051|\n",
      "|2017-03| 64.84130494490914| 64.76434906669284| 0.07695587821629601|  0.4997134949110131|\n",
      "|2017-04| 66.17157946134868| 66.23894781815379|-0.06736835680510467| -0.4374568623708095|\n",
      "|2017-05| 68.91727308793502| 68.82818222045898| 0.08909086747603112|  0.5785121264677345|\n",
      "|2017-06|  70.5181815407493| 70.56181820956144|-0.04363666881214101| -0.2833549922866299|\n",
      "|2017-07| 72.01050033569337| 71.84349975585937| 0.16700057983399574|   1.084419349571401|\n",
      "|2017-08| 72.81695755668308|  72.7156518023947| 0.10130575428837574|  0.6578295733011411|\n",
      "|2017-09| 74.34450073242188|  74.3654998779297|-0.02099914550781...|-0.13635808771308663|\n",
      "|2017-10| 77.93954571810636| 77.89318119395863| 0.04636452414773373|  0.3010683386216476|\n",
      "|2017-11| 83.71761903308686| 83.64523824055989| 0.07238079252697105|  0.4700051462790328|\n",
      "|2017-12|   84.758500289917| 84.83599967956543| -0.0774993896484375| -0.5032427899249188|\n",
      "|2018-01| 90.07523781912667| 89.96666681198846| 0.10857100713820955|  0.7050065398585036|\n",
      "|2018-02| 91.36789462440892| 91.43736829255757|-0.06947366814864608| -0.4511277152509486|\n",
      "|2018-03| 92.89904748825799| 93.23047601609002|-0.33142852783203125| -2.1521332976105927|\n",
      "|2018-04| 93.21476164318267| 93.53095318022228|-0.31619153703961445| -2.0531917989585353|\n",
      "|2018-05| 96.98136381669478| 96.63272718949752|  0.3486366271972656|  2.2638742025796468|\n",
      "|2018-06|100.56190454392205|100.66571517217727|-0.10381062825521781| -0.6740949886702455|\n",
      "|2018-07| 104.6385730561756|104.58571479434059|0.052858261835012854|  0.3432354664611224|\n",
      "|2018-08|108.68434740149456|108.45391281791355| 0.23043458358101532|  1.4963284648117878|\n",
      "+-------+------------------+------------------+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_daily_return(period=\"month\", start_price=15.4, nb_shares=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "dac1b154",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+------------------+--------------------+-------------------+\n",
      "|Date|        Close_mean|         Open_mean|                diff|            daily_r|\n",
      "+----+------------------+------------------+--------------------+-------------------+\n",
      "|2017| 71.98402421502954| 71.95430287516925|  0.0297213398602878| 0.1929957133784922|\n",
      "|2018|101.03398411967365|101.12235092831799|-0.08836680864433788|-0.5738104457424538|\n",
      "|2019|130.38202400813026|130.33904787093874| 0.04297613719151627| 0.2790658259189368|\n",
      "|2020| 190.8616180419922|190.76480678836674| 0.09681125362544662| 0.6286445040613418|\n",
      "+----+------------------+------------------+--------------------+-------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_daily_return(\"year\", start_price=15.4, nb_shares=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "599877c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
