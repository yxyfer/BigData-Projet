{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6dca563",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#BigData---Final-Project\" data-toc-modified-id=\"BigData---Final-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>BigData - Final Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-The-Data\" data-toc-modified-id=\"Loading-The-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loading The Data</a></span></li><li><span><a href=\"#Exploring-The-Data\" data-toc-modified-id=\"Exploring-The-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Exploring The Data</a></span></li><li><span><a href=\"#Analysis\" data-toc-modified-id=\"Analysis-1.3\"><span class=\"toc-item-num\">1.3&nbsp;&nbsp;</span>Analysis</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d16f4d",
   "metadata": {},
   "source": [
    "# BigData - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce715a02",
   "metadata": {},
   "source": [
    "__AUTHORS__:\n",
    "  - Théo Perinet (22172 - theo.perinet)\n",
    "  - Mathieu Rivier (23553 - mathieu.rivier)\n",
    "  - Marc Monteil (23742 - marc.monteil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38335eff",
   "metadata": {},
   "source": [
    "###### To Use when you are on google collab\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz  \n",
    "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea659e8b",
   "metadata": {},
   "source": [
    "###### TO USE WHEN YOU ARE ON GOOGLE COLLAB\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80976068",
   "metadata": {},
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8e3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_application_name = \"WannaFlop_Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8bad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/SPARK/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/20 09:35:21 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(spark_application_name).getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0926b5",
   "metadata": {},
   "source": [
    "## Exploring The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e4cdcaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType, StructType,StructField\n",
    "from pyspark.sql.functions import desc\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "b56d2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class read_info(object):\n",
    "    def __init__(self, file_path, header=False, delimiter=';', schema=None):\n",
    "        self.file_path = file_path\n",
    "        self.header = header\n",
    "        self.delimiter = delimiter\n",
    "        self.schema = schema\n",
    "\n",
    "        self.df = self._load_df()\n",
    "\n",
    "        #self.df_abstract = self._get_df_abstract()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self._nb_rows()} \\n{self.df.printSchema()} \\n{self.get_df_abstract()}\\n {self.show_missing()}\\n{self._get_stats()}\"\n",
    "\n",
    "    def show_missing(self):\n",
    "        print(\"Missing Data per column:\")\n",
    "        self._count_missing().show()\n",
    "\n",
    "    def _get_num_cols(self):\n",
    "        num_cols = [\n",
    "            f.name for f in self.df.schema.fields\n",
    "            if isinstance(f.dataType, DoubleType) or\n",
    "            isinstance(f.dataType, IntegerType)\n",
    "        ]\n",
    "        \n",
    "        return num_cols\n",
    "    def _get_rounded_df(self):\n",
    "        rounded_df = self.df\n",
    "        dbl_cols = self._get_num_cols()\n",
    "        for col in dbl_cols:\n",
    "            rounded_df = rounded_df.withColumn(col, func.round('high'))\n",
    "\n",
    "        return rounded_df\n",
    "\n",
    "    def get_df_abstract(self):\n",
    "        rounded_df = self._get_rounded_df()\n",
    "\n",
    "        # First 40 rows\n",
    "        print(\"First 40 rows:\")\n",
    "        rounded_df.show(40)\n",
    "\n",
    "        # Last 40 rows\n",
    "        print(\"Last 40 rows:\")\n",
    "        rounded_df = rounded_df.withColumn(\n",
    "            \"index\", monotonically_increasing_id()\n",
    "        )\n",
    "        rounded_df.orderBy(desc(\"index\")).drop(\"index\").show(40)\n",
    "\n",
    "    def _get_periodicity(self):\n",
    "        self.df['data'][0]\n",
    "\n",
    "    def _nb_rows(self):\n",
    "        # Number of total rows\n",
    "        print(\"Number of rows: \" + str(self.df.count()) + \"\\n\")\n",
    "\n",
    "    def _handle_csv(self):\n",
    "        '''\n",
    "        @description: Read the csv file and return a Spark DataFrame\n",
    "\n",
    "        @arg csv_file_path: Path to the csv file\n",
    "        @arg header: boolean whether to load a header or not\n",
    "        @arg delimiter: which delimiter to use by default\n",
    "        '''\n",
    "        return spark.read.option(\"inferSchema\", \"true\").option(\"nullValue\", \"null\").csv(\n",
    "            self.file_path,\n",
    "            sep=self.delimiter,\n",
    "            schema=self.schema,\n",
    "            header=self.header,\n",
    "        )\n",
    "    \n",
    "    def _handle_json(self):\n",
    "        return spark.read.json(self.file_path)\n",
    "\n",
    "    def _load_df(self):\n",
    "        ####### ADD TRY CATCH #####\n",
    "        extension = self.file_path.split(\".\")[-1]\n",
    "\n",
    "        df = None\n",
    "        if extension == 'json':\n",
    "            df = self._handle_json()\n",
    "        elif extension == 'csv':\n",
    "            df = self._handle_csv()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _count_missing(self):\n",
    "        cols = self.df.columns\n",
    "        cols.remove('Date')\n",
    "        return self.df.select(\n",
    "            [\n",
    "                count(when(isnan(c) | col(c).isNull(), c)).alias(c)\n",
    "                for c in cols\n",
    "            ]\n",
    "        )\n",
    "        #.show()\n",
    "        \n",
    "    def _get_stats(self):\n",
    "        self.df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "0dd4ffc0",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'h' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [60]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[43mh\u001b[49m)\n\u001b[1;32m      2\u001b[0m h\u001b[38;5;241m.\u001b[39mremove(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(h)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'h' is not defined"
     ]
    }
   ],
   "source": [
    "print(h)\n",
    "h.remove('Date')\n",
    "print(h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e4ed594d",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_schema = StructType([\n",
    "    StructField('Date', DateType(), True),\n",
    "    StructField('High', DoubleType(), True),\n",
    "    StructField('Low', DoubleType(), True),\n",
    "    StructField('Open', DoubleType(), True),\n",
    "    StructField('Close', DoubleType(), True),\n",
    "    StructField('Volume', IntegerType(), True),\n",
    "    StructField('Adj Close', DoubleType(), True),\n",
    "    StructField('company_name', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "276a609a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'spark' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [65]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m AMZN \u001b[38;5;241m=\u001b[39m \u001b[43mread_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstocks_data/AMAZON.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mschema\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mamzn_schema\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mread_info.__init__\u001b[0;34m(self, file_path, header, delimiter, schema)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter \u001b[38;5;241m=\u001b[39m delimiter\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema \u001b[38;5;241m=\u001b[39m schema\n\u001b[0;32m----> 8\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_load_df\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mread_info._load_df\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     80\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_handle_json()\n\u001b[1;32m     81\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m extension \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcsv\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m---> 82\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_handle_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "Input \u001b[0;32mIn [59]\u001b[0m, in \u001b[0;36mread_info._handle_csv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_handle_csv\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     57\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    @description: Read the csv file and return a Spark DataFrame\u001b[39;00m\n\u001b[1;32m     59\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     62\u001b[0m \u001b[38;5;124;03m    @arg delimiter: which delimiter to use by default\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m---> 64\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mspark\u001b[49m\u001b[38;5;241m.\u001b[39mread\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minferSchema\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrue\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39moption(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnullValue\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnull\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mcsv(\n\u001b[1;32m     65\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfile_path,\n\u001b[1;32m     66\u001b[0m         sep\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter,\n\u001b[1;32m     67\u001b[0m         schema\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mschema,\n\u001b[1;32m     68\u001b[0m         header\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mheader,\n\u001b[1;32m     69\u001b[0m     )\n",
      "\u001b[0;31mNameError\u001b[0m: name 'spark' is not defined"
     ]
    }
   ],
   "source": [
    "AMZN = read_info('stocks_data/AMAZON.csv', header=True, delimiter=',', schema=amzn_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "05cbf75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<stock_info.Stock object at 0x11330e3a0>\n"
     ]
    }
   ],
   "source": [
    "print(AMZN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "39f70176",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### A FAIRE !!!! UN SCHEMA !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "04ae8afa",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stock' object has no attribute 'get_df_abstract'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [68]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_df_abstract\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stock' object has no attribute 'get_df_abstract'"
     ]
    }
   ],
   "source": [
    "AMZN.get_df_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "82df148b",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stock' object has no attribute 'show_missing'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [69]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_missing\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stock' object has no attribute 'show_missing'"
     ]
    }
   ],
   "source": [
    "AMZN.show_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "c0d7dea1",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'Stock' object has no attribute '_get_stats'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [70]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_stats\u001b[49m()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Stock' object has no attribute '_get_stats'"
     ]
    }
   ],
   "source": [
    "AMZN._get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "417d13f0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Can't extract value from date#4536: need struct type but got date",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [71]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatediff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2478\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Can't extract value from date#4536: need struct type but got date"
     ]
    }
   ],
   "source": [
    "AMZN.df.withColumn(\"test\", \n",
    "              func.datediff(AMZN.df[\"date\"][0], AMZN.df[\"date\"][1])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "f8727761",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Date[2]'>"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df[\"Date\"].getItem(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "66fd01da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 1, 3)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df.first()['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "a9511232",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '__get_item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_item\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '__get_item'"
     ]
    }
   ],
   "source": [
    "AMZN.df.__get_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "648df822",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'second'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [75]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecond\u001b[49m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'second'"
     ]
    }
   ],
   "source": [
    "AMZN.df.second()['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0e43b680",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspark.sql.functions' has no attribute 'getrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [76]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetrows\u001b[49m(AMZN\u001b[38;5;241m.\u001b[39mdf, rownums\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyspark.sql.functions' has no attribute 'getrows'"
     ]
    }
   ],
   "source": [
    "func.getrows(AMZN.df, rownums=[0, 2]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "338ad834",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df[0].__getitem__(\"Date\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94e48035",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4379c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.select('Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a968c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd3187e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "\n",
    "my_window = Window.partitionBy().orderBy(\"Date\")\n",
    "\n",
    "df = AMZN.df.withColumn(\"prev_value\", F.lag(AMZN.df.Date).over(my_window))\n",
    "df = df.withColumn(\"diff\", F.when(F.isnull(F.datediff(df.Date, df.prev_value)), 0)\n",
    "                              .otherwise(F.datediff(df.Date, df.prev_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "091f75f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(\"diff\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f88ce60",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a30bac8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.select(mean('diff')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e274cc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.stat.corr('High', 'Low')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5be878e",
   "metadata": {},
   "source": [
    "TODO: Create function to compute per month week year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2225ad70",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.select(mean (\"Close\")).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a0a2c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_mean(df, col):\n",
    "    return df.select(mean (col)).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e0ddb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_col_mean(AMZN.df, \"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59dece69",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.weekofyear(\"day\").alias(\"date_by_week\")).agg(sum(\"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ffbd5a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.weekofyear(\"day\").alias(\"date_by_week\")).agg(sum(\"Close\")).orderBy(\"date_by_week\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07fba243",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.withColumn(\"Date\",func.date_sub(func.next_day(col(\"Date\"),\"sunday\"),7)).groupBy(\"Date\").agg(sum(\"Close\").cast(\"int\").alias(\"Close_total\")).orderBy(\"week_strt_day\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d70c79b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(\"Date\").select(\"Close\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "054cb285",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.month(\"Date\").alias(\"hour\")).agg(mean(\"Close\").alias(\"close_mean\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75bf0fd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.groupBy(func.year(\"Date\").alias(\"hour\")).agg(mean(\"Close\").alias(\"close_mean\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66cde3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4d35d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_avg(AMZN.df, \"Close\", func.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcf6a9a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_avg(AMZN.df, \"Open\", func.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a7e2421",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exploration(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def get_oc_avg(self, fun):\n",
    "        close = self._compute_avg(self.df, \"Close\", fun)\n",
    "        opening = self._compute_avg(self.df, \"Open\", fun)\n",
    "\n",
    "        return close.join(\n",
    "            opening, opening.Open_new_time == close.Close_new_time, \"inner\"\n",
    "        ).orderBy(\"Close_new_time\").select(\n",
    "            close.Close_new_time, close.Close_mean, opening.Open_mean\n",
    "        )\n",
    "\n",
    "    def _compute_avg(self, df, col, fun):\n",
    "        return df.groupBy(fun(\"Date\").alias(col + \"_new_time\")).agg(\n",
    "            mean(col).alias(col + \"_mean\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d71ede51",
   "metadata": {},
   "outputs": [],
   "source": [
    "exAMZN = Exploration(AMZN.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "722bf1f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "exAMZN.get_oc_avg(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adddc67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "exAMZN.get_oc_avg(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9136d41c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_change(period=None):\n",
    "    df = AMZN.df\n",
    "    if period:\n",
    "        df= exAMZN.get_oc_avg(period)\n",
    "   \n",
    "    return  df.withColumn('diff', ( df['Close_mean'] - df['Open_mean'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "882ddca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price_change(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28abc395",
   "metadata": {},
   "outputs": [],
   "source": [
    "get_price_change(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "333d482d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8400e05b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66c8f63e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1e6e6dc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a103611",
   "metadata": {},
   "outputs": [],
   "source": [
    "from stock_info import Stock"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "19debd77",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN = Stock('stocks_data/MICROSOFT.csv', header=True, delimiter=',', schema=amzn_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "e3c1516a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      "\n",
      "First 40 rows:\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|      Date|High| Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|2017-01-03|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-04|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-05|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-06|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-09|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-10|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-11|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-12|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-13|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-17|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-18|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-19|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-20|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-23|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-24|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-25|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-26|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-01-27|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-30|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-31|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-02|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-02-03|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-06|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-07|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-08|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-09|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-10|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-13|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-14|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-15|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-16|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-17|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-21|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-22|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-23|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-24|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-27|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-28|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-03-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Last 40 rows:\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|      Date| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|2020-12-02|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-12-01|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-30|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-27|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-11-25|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-24|214.0|214.0|214.0|214.0| 214.0|    214.0|   MICROSOFT|\n",
      "|2020-11-23|212.0|212.0|212.0|212.0| 212.0|    212.0|   MICROSOFT|\n",
      "|2020-11-20|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-19|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-18|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-17|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-16|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-13|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-12|219.0|219.0|219.0|219.0| 219.0|    219.0|   MICROSOFT|\n",
      "|2020-11-11|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-10|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-09|228.0|228.0|228.0|228.0| 228.0|    228.0|   MICROSOFT|\n",
      "|2020-11-06|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-05|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-04|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-03|208.0|208.0|208.0|208.0| 208.0|    208.0|   MICROSOFT|\n",
      "|2020-11-02|205.0|205.0|205.0|205.0| 205.0|    205.0|   MICROSOFT|\n",
      "|2020-10-30|204.0|204.0|204.0|204.0| 204.0|    204.0|   MICROSOFT|\n",
      "|2020-10-29|207.0|207.0|207.0|207.0| 207.0|    207.0|   MICROSOFT|\n",
      "|2020-10-28|209.0|209.0|209.0|209.0| 209.0|    209.0|   MICROSOFT|\n",
      "|2020-10-27|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-10-26|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-23|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-22|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-21|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-20|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-19|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-16|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-15|220.0|220.0|220.0|220.0| 220.0|    220.0|   MICROSOFT|\n",
      "|2020-10-14|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-13|225.0|225.0|225.0|225.0| 225.0|    225.0|   MICROSOFT|\n",
      "|2020-10-12|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-09|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-08|211.0|211.0|211.0|211.0| 211.0|    211.0|   MICROSOFT|\n",
      "|2020-10-07|210.0|210.0|210.0|210.0| 210.0|    210.0|   MICROSOFT|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Number of rows: 987\n",
      "\n",
      "Stock Stats:\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|summary| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|  count|987.0|987.0|987.0|987.0| 987.0|    987.0|         987|\n",
      "|   mean|124.0|124.0|124.0|124.0| 124.0|    124.0|        null|\n",
      "| stddev| 46.0| 46.0| 46.0| 46.0|  46.0|     46.0|        null|\n",
      "|    min| 63.0| 63.0| 63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|    25%| 86.0| 86.0| 86.0| 86.0|  86.0|     86.0|        null|\n",
      "|    50%|111.0|111.0|111.0|111.0| 111.0|    111.0|        null|\n",
      "|    75%|152.0|152.0|152.0|152.0| 152.0|    152.0|        null|\n",
      "|    max|233.0|233.0|233.0|233.0| 233.0|    233.0|   MICROSOFT|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "\n",
      "Missing Data per column:\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|High|Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|   0|  0|   0|    0|   987|        0|           0|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\n",
       "            None\n",
       "\n",
       "            None\n",
       "\n",
       "            None\n",
       "\n",
       "            None\n",
       "\n",
       "            None"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.explore"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "f9ed929d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 987\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore._nb_rows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "d3fa42bf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore._print_schema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "32f0c103",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 40 rows:\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|      Date|High| Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "|2017-01-03|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-04|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-05|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-06|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-09|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-10|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-11|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-12|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-13|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-17|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-18|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-19|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-20|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-23|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-01-24|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-25|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-01-26|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-01-27|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-30|66.0|66.0|66.0| 66.0|  66.0|     66.0|   MICROSOFT|\n",
      "|2017-01-31|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-02|63.0|63.0|63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|2017-02-03|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-06|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-07|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-08|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-09|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-10|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-13|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-14|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-15|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-16|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-17|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-21|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-22|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-02-23|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-24|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-27|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "|2017-02-28|64.0|64.0|64.0| 64.0|  64.0|     64.0|   MICROSOFT|\n",
      "|2017-03-01|65.0|65.0|65.0| 65.0|  65.0|     65.0|   MICROSOFT|\n",
      "+----------+----+----+----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Last 40 rows:\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|      Date| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|2020-12-02|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-12-01|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-30|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-27|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-11-25|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-24|214.0|214.0|214.0|214.0| 214.0|    214.0|   MICROSOFT|\n",
      "|2020-11-23|212.0|212.0|212.0|212.0| 212.0|    212.0|   MICROSOFT|\n",
      "|2020-11-20|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-19|213.0|213.0|213.0|213.0| 213.0|    213.0|   MICROSOFT|\n",
      "|2020-11-18|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-11-17|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-16|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-13|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-12|219.0|219.0|219.0|219.0| 219.0|    219.0|   MICROSOFT|\n",
      "|2020-11-11|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-10|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-11-09|228.0|228.0|228.0|228.0| 228.0|    228.0|   MICROSOFT|\n",
      "|2020-11-06|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-05|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-11-04|218.0|218.0|218.0|218.0| 218.0|    218.0|   MICROSOFT|\n",
      "|2020-11-03|208.0|208.0|208.0|208.0| 208.0|    208.0|   MICROSOFT|\n",
      "|2020-11-02|205.0|205.0|205.0|205.0| 205.0|    205.0|   MICROSOFT|\n",
      "|2020-10-30|204.0|204.0|204.0|204.0| 204.0|    204.0|   MICROSOFT|\n",
      "|2020-10-29|207.0|207.0|207.0|207.0| 207.0|    207.0|   MICROSOFT|\n",
      "|2020-10-28|209.0|209.0|209.0|209.0| 209.0|    209.0|   MICROSOFT|\n",
      "|2020-10-27|215.0|215.0|215.0|215.0| 215.0|    215.0|   MICROSOFT|\n",
      "|2020-10-26|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-23|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-22|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-21|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-20|217.0|217.0|217.0|217.0| 217.0|    217.0|   MICROSOFT|\n",
      "|2020-10-19|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-16|222.0|222.0|222.0|222.0| 222.0|    222.0|   MICROSOFT|\n",
      "|2020-10-15|220.0|220.0|220.0|220.0| 220.0|    220.0|   MICROSOFT|\n",
      "|2020-10-14|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-13|225.0|225.0|225.0|225.0| 225.0|    225.0|   MICROSOFT|\n",
      "|2020-10-12|224.0|224.0|224.0|224.0| 224.0|    224.0|   MICROSOFT|\n",
      "|2020-10-09|216.0|216.0|216.0|216.0| 216.0|    216.0|   MICROSOFT|\n",
      "|2020-10-08|211.0|211.0|211.0|211.0| 211.0|    211.0|   MICROSOFT|\n",
      "|2020-10-07|210.0|210.0|210.0|210.0| 210.0|    210.0|   MICROSOFT|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore.get_df_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "9fe1a15f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data per column:\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|High|Low|Open|Close|Volume|Adj Close|company_name|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "|   0|  0|   0|    0|   987|        0|           0|\n",
      "+----+---+----+-----+------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore.get_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "92fb95ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stock Stats:\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|summary| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "|  count|987.0|987.0|987.0|987.0| 987.0|    987.0|         987|\n",
      "|   mean|124.0|124.0|124.0|124.0| 124.0|    124.0|        null|\n",
      "| stddev| 46.0| 46.0| 46.0| 46.0|  46.0|     46.0|        null|\n",
      "|    min| 63.0| 63.0| 63.0| 63.0|  63.0|     63.0|   MICROSOFT|\n",
      "|    25%| 86.0| 86.0| 86.0| 86.0|  86.0|     86.0|        null|\n",
      "|    50%|111.0|111.0|111.0|111.0| 111.0|    111.0|        null|\n",
      "|    75%|152.0|152.0|152.0|152.0| 152.0|    152.0|        null|\n",
      "|    max|233.0|233.0|233.0|233.0| 233.0|    233.0|   MICROSOFT|\n",
      "+-------+-----+-----+-----+-----+------+---------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.explore.get_stats()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61659a6f",
   "metadata": {},
   "source": [
    "## Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5cabf6a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|\n",
      "+--------------+------------------+------------------+\n",
      "|             1|105.85831272171204|105.77626520179841|\n",
      "|             2|110.53223670156379| 110.4122371673584|\n",
      "|             3|105.93367846258755| 105.8214945738343|\n",
      "|             4|113.94256135894031|114.03365874871974|\n",
      "|             5|117.16558128179506|116.99720932716546|\n",
      "|             6|124.02905919692095|123.88423551671646|\n",
      "|             7|132.13705929026884|132.14776458740235|\n",
      "|             8| 131.1935954576128|130.99910136019247|\n",
      "|             9|134.58337545394897| 134.8017505645752|\n",
      "|            10|134.58111139933268|134.83355534871419|\n",
      "|            11|137.26853663746903|137.19707321539158|\n",
      "|            12|118.49608095230595|   118.63177428707|\n",
      "+--------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_oc_avg(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "0eeb8958",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|\n",
      "+--------------+------------------+------------------+\n",
      "|          2017| 71.98402421502954| 71.95430287516925|\n",
      "|          2018|101.03398411967365|101.12235092831799|\n",
      "|          2019|130.38202400813026|130.33904787093874|\n",
      "|          2020| 190.8616180419922|190.76480678836674|\n",
      "+--------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_oc_avg(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "65979857",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+--------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|                diff|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "|             1|105.85831272171204|105.77626520179841| 0.08204751991362969|\n",
      "|             2|110.53223670156379| 110.4122371673584|   0.119999534205391|\n",
      "|             3|105.93367846258755| 105.8214945738343| 0.11218388875325047|\n",
      "|             4|113.94256135894031|114.03365874871974|-0.09109738977943493|\n",
      "|             5|117.16558128179506|116.99720932716546| 0.16837195462959187|\n",
      "|             6|124.02905919692095|123.88423551671646| 0.14482368020449599|\n",
      "|             7|132.13705929026884|132.14776458740235|-0.01070529713351...|\n",
      "|             8| 131.1935954576128|130.99910136019247| 0.19449409742031776|\n",
      "|             9|134.58337545394897| 134.8017505645752| -0.2183751106262264|\n",
      "|            10|134.58111139933268|134.83355534871419|-0.25244394938150094|\n",
      "|            11|137.26853663746903|137.19707321539158| 0.07146342207744283|\n",
      "|            12|118.49608095230595|   118.63177428707|-0.13569333476405632|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_price_change(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "01aebe47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+--------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|                diff|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "|          2017| 71.98402421502954| 71.95430287516925|  0.0297213398602878|\n",
      "|          2018|101.03398411967365|101.12235092831799|-0.08836680864433788|\n",
      "|          2019|130.38202400813026|130.33904787093874| 0.04297613719151627|\n",
      "|          2020| 190.8616180419922|190.76480678836674| 0.09681125362544662|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.analysis.get_price_change(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "db0e748d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+\n",
      "|   Date|        avg(Close)|\n",
      "+-------+------------------+\n",
      "|2020-06|192.69954681396484|\n",
      "|2019-10|139.22913062054178|\n",
      "|2020-12| 215.1685028076172|\n",
      "|2018-10|  109.207391490107|\n",
      "|2020-02|178.71947358783922|\n",
      "|2017-09| 74.34450073242188|\n",
      "|2019-11|148.09550018310546|\n",
      "|2017-10| 77.93954571810636|\n",
      "|2017-05| 68.91727308793502|\n",
      "|2018-06|100.56190454392205|\n",
      "|2019-03|115.13381013416108|\n",
      "|2017-11| 83.71761903308686|\n",
      "|2018-03| 92.89904748825799|\n",
      "|2020-05|182.34249954223634|\n",
      "|2017-03| 64.84130494490914|\n",
      "|2018-02| 91.36789462440892|\n",
      "|2017-08| 72.81695755668308|\n",
      "|2019-07|  138.102727023038|\n",
      "|2017-06|  70.5181815407493|\n",
      "|2017-02| 64.11368440326892|\n",
      "+-------+------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "(AMZN.df.withColumn('Date', func.date_format(func.col('Date'), 'yyyy-MM'))\n",
    ".groupBy('Date')\n",
    ".agg(func.mean('Close'))\n",
    ").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "d06b2305",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'str' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [145]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43manalysis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_compute_avg\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmonth\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m~/Library/Mobile Documents/com~apple~CloudDocs/EPITA/prog/BigData/Project/stock_info.py:191\u001b[0m, in \u001b[0;36m_compute_avg\u001b[0;34m(self, df, col, period)\u001b[0m\n\u001b[1;32m    187\u001b[0m             date = {\"month\": \"yyyy-MM\", \"year\": \"yyyy\"}\n\u001b[1;32m    188\u001b[0m             return df.withColumn('Date', func.date_format(func.col('Date'),\n\u001b[1;32m    189\u001b[0m             date[period])).groupBy('Date').agg(func.mean(col)).orderBy(col(\"Date\").asc())\n\u001b[0;32m--> 191\u001b[0m #            return df.groupBy(fun(\"Date\").alias(col + \"_new_time\")).agg(\n\u001b[1;32m    192\u001b[0m #                mean(col).alias(col + \"_mean\")\n\u001b[1;32m    193\u001b[0m #            )\n",
      "\u001b[0;31mTypeError\u001b[0m: 'str' object is not callable"
     ]
    }
   ],
   "source": [
    "AMZN.analysis._compute_avg(AMZN.df, \"Close\", \"month\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5be8b05b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
