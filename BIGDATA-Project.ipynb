{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6dca563",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#BigData---Final-Project\" data-toc-modified-id=\"BigData---Final-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>BigData - Final Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-The-Data\" data-toc-modified-id=\"Loading-The-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loading The Data</a></span></li><li><span><a href=\"#Exploring-The-Data\" data-toc-modified-id=\"Exploring-The-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Exploring The Data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d16f4d",
   "metadata": {},
   "source": [
    "# BigData - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce715a02",
   "metadata": {},
   "source": [
    "__AUTHORS__:\n",
    "  - ThÃ©o Perinet (22172 - theo.perinet)\n",
    "  - Mathieu Rivier (23553 - mathieu.rivier)\n",
    "  - Marc Monteil (23742 - marc.monteil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38335eff",
   "metadata": {},
   "source": [
    "###### To Use when you are on google collab\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz  \n",
    "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea659e8b",
   "metadata": {},
   "source": [
    "###### TO USE WHEN YOU ARE ON GOOGLE COLLAB\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80976068",
   "metadata": {},
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d92cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1d8e3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_application_name = \"WannaFlop_Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "cf8bad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/06 17:06:50 WARN Utils: Your hostname, Mathieus-MacBook-Pro.local resolves to a loopback address: 127.0.0.1; using 172.27.99.57 instead (on interface feth4588)\n",
      "22/05/06 17:06:50 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/SPARK/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/06 17:06:51 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(spark_application_name).getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0926b5",
   "metadata": {},
   "source": [
    "## Exploring The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b56d2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class read_info(object):\n",
    "    def __init__(self, file_path, header=False, delimiter=';'):\n",
    "        self.file_path = file_path\n",
    "        self.header = header\n",
    "        self.delimiter = delimiter\n",
    "        \n",
    "        self.df = self._load_df()\n",
    "        \n",
    "        self.df_abstract = self._get_df_abstract()\n",
    "        \n",
    "    def __repr__(self): \n",
    "        return self.df.printSchema()\n",
    "    \n",
    "    def _get_df_abstract(self):\n",
    "        # Show the First 10 lines\n",
    "        self.df.select(round('high', 0)).show(10)\n",
    "        \n",
    "    def _nb_rows(self):\n",
    "        # Number of total rows\n",
    "        print(\"Number of rows: \" + str(df.count()))\n",
    "\n",
    "\n",
    "    def _handle_csv(self):\n",
    "        '''\n",
    "        @description: Read the csv file and return a Spark DataFrame\n",
    "\n",
    "        @arg csv_file_path: Path to the csv file\n",
    "        @arg header: boolean whether to load a header or not\n",
    "        @arg delimiter: which delimiter to use by default\n",
    "        '''\n",
    "        return spark.read.csv(self.file_path, sep=self.delimiter, header=self.header)\n",
    "\n",
    "\n",
    "    def _handle_json(self):\n",
    "        return spark.read.json(self.file_path)\n",
    "\n",
    "\n",
    "    def _load_df(self):\n",
    "        ####### ADD TRY CATCH #####\n",
    "        extension = self.file_path.split(\".\")[-1]\n",
    "\n",
    "        df = None\n",
    "        if extension == 'json':\n",
    "            df = self._handle_json()\n",
    "        elif extension == 'csv':\n",
    "            df = self._handle_csv()\n",
    "\n",
    "        return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "276a609a",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "type str doesn't define __round__ method",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [23]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m AMZN \u001b[38;5;241m=\u001b[39m \u001b[43mread_info\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstocks_data/AMAZON.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mread_info.__init__\u001b[0;34m(self, file_path, header, delimiter)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelimiter \u001b[38;5;241m=\u001b[39m delimiter\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_df()\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf_abstract \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_df_abstract\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mread_info._get_df_abstract\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_get_df_abstract\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;66;03m# Show the First 10 lines\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mselect(\u001b[38;5;28;43mround\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mhigh\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39mshow(\u001b[38;5;241m10\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: type str doesn't define __round__ method"
     ]
    }
   ],
   "source": [
    "AMZN = read_info('stocks_data/AMAZON.csv', header=True, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e67c184e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "print(AMZN.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "05cbf75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- Date: string (nullable = true)\n",
      " |-- High: string (nullable = true)\n",
      " |-- Low: string (nullable = true)\n",
      " |-- Open: string (nullable = true)\n",
      " |-- Close: string (nullable = true)\n",
      " |-- Volume: string (nullable = true)\n",
      " |-- Adj Close: string (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      "\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "__str__ returned non-string (type NoneType)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [19]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAMZN\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: __str__ returned non-string (type NoneType)"
     ]
    }
   ],
   "source": [
    "print(AMZN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "39f70176",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### A FAIRE !!!! UN SCHEMA !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82df148b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
