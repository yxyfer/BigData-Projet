{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6dca563",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#BigData---Final-Project\" data-toc-modified-id=\"BigData---Final-Project-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>BigData - Final Project</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loading-The-Data\" data-toc-modified-id=\"Loading-The-Data-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Loading The Data</a></span></li><li><span><a href=\"#Exploring-The-Data\" data-toc-modified-id=\"Exploring-The-Data-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Exploring The Data</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76d16f4d",
   "metadata": {},
   "source": [
    "# BigData - Final Project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce715a02",
   "metadata": {},
   "source": [
    "__AUTHORS__:\n",
    "  - Théo Perinet (22172 - theo.perinet)\n",
    "  - Mathieu Rivier (23553 - mathieu.rivier)\n",
    "  - Marc Monteil (23742 - marc.monteil)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38335eff",
   "metadata": {},
   "source": [
    "###### To Use when you are on google collab\n",
    "!apt-get install openjdk-11-jdk-headless -qq > /dev/null\n",
    "!wget -q https://downloads.apache.org/spark/spark-3.2.1/spark-3.2.1-bin-hadoop2.7.tgz  \n",
    "!tar xf spark-3.2.1-bin-hadoop2.7.tgz\n",
    "!pip install -q findspark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea659e8b",
   "metadata": {},
   "source": [
    "###### TO USE WHEN YOU ARE ON GOOGLE COLLAB\n",
    "import os\n",
    "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n",
    "os.environ[\"SPARK_HOME\"] = \"/content/spark-3.2.1-bin-hadoop2.7\"\n",
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80976068",
   "metadata": {},
   "source": [
    "## Loading The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d92cbfca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d8e3e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark_application_name = \"WannaFlop_Project\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf8bad11",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: An illegal reflective access operation has occurred\n",
      "WARNING: Illegal reflective access by org.apache.spark.unsafe.Platform (file:/usr/local/Cellar/apache-spark/3.2.1/SPARK/jars/spark-unsafe_2.12-3.2.1.jar) to constructor java.nio.DirectByteBuffer(long,int)\n",
      "WARNING: Please consider reporting this to the maintainers of org.apache.spark.unsafe.Platform\n",
      "WARNING: Use --illegal-access=warn to enable warnings of further illegal reflective access operations\n",
      "WARNING: All illegal access operations will be denied in a future release\n",
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "22/05/20 08:11:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "spark = (SparkSession.builder.appName(spark_application_name).getOrCreate())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d0926b5",
   "metadata": {},
   "source": [
    "## Exploring The Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4985b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import col,isnan,when,count\n",
    "from pyspark.sql.functions import monotonically_increasing_id\n",
    "from pyspark.sql.types import DoubleType, IntegerType, StringType, DateType, StructType,StructField\n",
    "from pyspark.sql.functions import desc\n",
    "import pyspark.sql.functions as func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "b56d2f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "class read_info(object):\n",
    "    def __init__(self, file_path, header=False, delimiter=';', schema=None):\n",
    "        self.file_path = file_path\n",
    "        self.header = header\n",
    "        self.delimiter = delimiter\n",
    "        self.schema = schema\n",
    "\n",
    "        self.df = self._load_df()\n",
    "\n",
    "        #self.df_abstract = self._get_df_abstract()\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f\"{self._nb_rows()} \\n{self.df.printSchema()} \\n{self.get_df_abstract()}\\n {self.show_missing()}\\n{self._get_stats()}\"\n",
    "\n",
    "    def show_missing(self):\n",
    "        print(\"Missing Data per column:\")\n",
    "        self._count_missing().show()\n",
    "\n",
    "    def _get_num_cols(self):\n",
    "        num_cols = [\n",
    "            f.name for f in self.df.schema.fields\n",
    "            if isinstance(f.dataType, DoubleType) or\n",
    "            isinstance(f.dataType, IntegerType)\n",
    "        ]\n",
    "        \n",
    "        return num_cols\n",
    "    def _get_rounded_df(self):\n",
    "        rounded_df = self.df\n",
    "        dbl_cols = self._get_num_cols()\n",
    "        for col in dbl_cols:\n",
    "            rounded_df = rounded_df.withColumn(col, func.round('high'))\n",
    "\n",
    "        return rounded_df\n",
    "\n",
    "    def get_df_abstract(self):\n",
    "        rounded_df = self._get_rounded_df()\n",
    "\n",
    "        # First 40 rows\n",
    "        print(\"First 40 rows:\")\n",
    "        rounded_df.show(40)\n",
    "\n",
    "        # Last 40 rows\n",
    "        print(\"Last 40 rows:\")\n",
    "        rounded_df = rounded_df.withColumn(\n",
    "            \"index\", monotonically_increasing_id()\n",
    "        )\n",
    "        rounded_df.orderBy(desc(\"index\")).drop(\"index\").show(40)\n",
    "\n",
    "    def _get_periodicity(self):\n",
    "        self.df['data'][0]\n",
    "\n",
    "    def _nb_rows(self):\n",
    "        # Number of total rows\n",
    "        print(\"Number of rows: \" + str(self.df.count()) + \"\\n\")\n",
    "\n",
    "    def _handle_csv(self):\n",
    "        '''\n",
    "        @description: Read the csv file and return a Spark DataFrame\n",
    "\n",
    "        @arg csv_file_path: Path to the csv file\n",
    "        @arg header: boolean whether to load a header or not\n",
    "        @arg delimiter: which delimiter to use by default\n",
    "        '''\n",
    "        return spark.read.option(\"inferSchema\", \"true\").option(\"nullValue\", \"null\").csv(\n",
    "            self.file_path,\n",
    "            sep=self.delimiter,\n",
    "            schema=self.schema,\n",
    "            header=self.header,\n",
    "        )\n",
    "    \n",
    "    def _handle_json(self):\n",
    "        return spark.read.json(self.file_path)\n",
    "\n",
    "    def _load_df(self):\n",
    "        ####### ADD TRY CATCH #####\n",
    "        extension = self.file_path.split(\".\")[-1]\n",
    "\n",
    "        df = None\n",
    "        if extension == 'json':\n",
    "            df = self._handle_json()\n",
    "        elif extension == 'csv':\n",
    "            df = self._handle_csv()\n",
    "\n",
    "        return df\n",
    "\n",
    "    def _count_missing(self):\n",
    "        return self.df.select(\n",
    "            [\n",
    "                count(when(isnan(c) | col(c).isNull(), c)).alias(c)\n",
    "                for c in self.df.columns\n",
    "            ]\n",
    "        )\n",
    "        #.show()\n",
    "        \n",
    "    def _get_stats(self):\n",
    "        self.df.summary().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "bed62e48",
   "metadata": {},
   "outputs": [],
   "source": [
    "amzn_schema = StructType([\n",
    "    StructField('Date', DateType(), True),\n",
    "    StructField('High', DoubleType(), True),\n",
    "    StructField('Low', DoubleType(), True),\n",
    "    StructField('Open', DoubleType(), True),\n",
    "    StructField('Close', DoubleType(), True),\n",
    "    StructField('Volume', IntegerType(), True),\n",
    "    StructField('Adj Close', DoubleType(), True),\n",
    "    StructField('company_name', StringType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "276a609a",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN = read_info('stocks_data/AMAZON.csv', header=True, delimiter=',', schema=amzn_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "05cbf75e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of rows: 987\n",
      "\n",
      "root\n",
      " |-- Date: date (nullable = true)\n",
      " |-- High: double (nullable = true)\n",
      " |-- Low: double (nullable = true)\n",
      " |-- Open: double (nullable = true)\n",
      " |-- Close: double (nullable = true)\n",
      " |-- Volume: integer (nullable = true)\n",
      " |-- Adj Close: double (nullable = true)\n",
      " |-- company_name: string (nullable = true)\n",
      "\n",
      "First 40 rows:\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|      Date| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|2017-01-03|759.0|759.0|759.0|759.0| 759.0|    759.0|      AMAZON|\n",
      "|2017-01-04|760.0|760.0|760.0|760.0| 760.0|    760.0|      AMAZON|\n",
      "|2017-01-05|782.0|782.0|782.0|782.0| 782.0|    782.0|      AMAZON|\n",
      "|2017-01-06|799.0|799.0|799.0|799.0| 799.0|    799.0|      AMAZON|\n",
      "|2017-01-09|802.0|802.0|802.0|802.0| 802.0|    802.0|      AMAZON|\n",
      "|2017-01-10|798.0|798.0|798.0|798.0| 798.0|    798.0|      AMAZON|\n",
      "|2017-01-11|800.0|800.0|800.0|800.0| 800.0|    800.0|      AMAZON|\n",
      "|2017-01-12|814.0|814.0|814.0|814.0| 814.0|    814.0|      AMAZON|\n",
      "|2017-01-13|822.0|822.0|822.0|822.0| 822.0|    822.0|      AMAZON|\n",
      "|2017-01-17|816.0|816.0|816.0|816.0| 816.0|    816.0|      AMAZON|\n",
      "|2017-01-18|812.0|812.0|812.0|812.0| 812.0|    812.0|      AMAZON|\n",
      "|2017-01-19|814.0|814.0|814.0|814.0| 814.0|    814.0|      AMAZON|\n",
      "|2017-01-20|816.0|816.0|816.0|816.0| 816.0|    816.0|      AMAZON|\n",
      "|2017-01-23|819.0|819.0|819.0|819.0| 819.0|    819.0|      AMAZON|\n",
      "|2017-01-24|824.0|824.0|824.0|824.0| 824.0|    824.0|      AMAZON|\n",
      "|2017-01-25|837.0|837.0|837.0|837.0| 837.0|    837.0|      AMAZON|\n",
      "|2017-01-26|844.0|844.0|844.0|844.0| 844.0|    844.0|      AMAZON|\n",
      "|2017-01-27|840.0|840.0|840.0|840.0| 840.0|    840.0|      AMAZON|\n",
      "|2017-01-30|834.0|834.0|834.0|834.0| 834.0|    834.0|      AMAZON|\n",
      "|2017-01-31|827.0|827.0|827.0|827.0| 827.0|    827.0|      AMAZON|\n",
      "|2017-02-01|834.0|834.0|834.0|834.0| 834.0|    834.0|      AMAZON|\n",
      "|2017-02-02|842.0|842.0|842.0|842.0| 842.0|    842.0|      AMAZON|\n",
      "|2017-02-03|818.0|818.0|818.0|818.0| 818.0|    818.0|      AMAZON|\n",
      "|2017-02-06|811.0|811.0|811.0|811.0| 811.0|    811.0|      AMAZON|\n",
      "|2017-02-07|816.0|816.0|816.0|816.0| 816.0|    816.0|      AMAZON|\n",
      "|2017-02-08|821.0|821.0|821.0|821.0| 821.0|    821.0|      AMAZON|\n",
      "|2017-02-09|825.0|825.0|825.0|825.0| 825.0|    825.0|      AMAZON|\n",
      "|2017-02-10|828.0|828.0|828.0|828.0| 828.0|    828.0|      AMAZON|\n",
      "|2017-02-13|843.0|843.0|843.0|843.0| 843.0|    843.0|      AMAZON|\n",
      "|2017-02-14|838.0|838.0|838.0|838.0| 838.0|    838.0|      AMAZON|\n",
      "|2017-02-15|843.0|843.0|843.0|843.0| 843.0|    843.0|      AMAZON|\n",
      "|2017-02-16|845.0|845.0|845.0|845.0| 845.0|    845.0|      AMAZON|\n",
      "|2017-02-17|847.0|847.0|847.0|847.0| 847.0|    847.0|      AMAZON|\n",
      "|2017-02-21|858.0|858.0|858.0|858.0| 858.0|    858.0|      AMAZON|\n",
      "|2017-02-22|858.0|858.0|858.0|858.0| 858.0|    858.0|      AMAZON|\n",
      "|2017-02-23|861.0|861.0|861.0|861.0| 861.0|    861.0|      AMAZON|\n",
      "|2017-02-24|846.0|846.0|846.0|846.0| 846.0|    846.0|      AMAZON|\n",
      "|2017-02-27|853.0|853.0|853.0|853.0| 853.0|    853.0|      AMAZON|\n",
      "|2017-02-28|854.0|854.0|854.0|854.0| 854.0|    854.0|      AMAZON|\n",
      "|2017-03-01|855.0|855.0|855.0|855.0| 855.0|    855.0|      AMAZON|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Last 40 rows:\n",
      "+----------+------+------+------+------+------+---------+------------+\n",
      "|      Date|  High|   Low|  Open| Close|Volume|Adj Close|company_name|\n",
      "+----------+------+------+------+------+------+---------+------------+\n",
      "|2020-12-02|3224.0|3224.0|3224.0|3224.0|3224.0|   3224.0|      AMAZON|\n",
      "|2020-12-01|3249.0|3249.0|3249.0|3249.0|3249.0|   3249.0|      AMAZON|\n",
      "|2020-11-30|3228.0|3228.0|3228.0|3228.0|3228.0|   3228.0|      AMAZON|\n",
      "|2020-11-27|3216.0|3216.0|3216.0|3216.0|3216.0|   3216.0|      AMAZON|\n",
      "|2020-11-25|3198.0|3198.0|3198.0|3198.0|3198.0|   3198.0|      AMAZON|\n",
      "|2020-11-24|3134.0|3134.0|3134.0|3134.0|3134.0|   3134.0|      AMAZON|\n",
      "|2020-11-23|3140.0|3140.0|3140.0|3140.0|3140.0|   3140.0|      AMAZON|\n",
      "|2020-11-20|3133.0|3133.0|3133.0|3133.0|3133.0|   3133.0|      AMAZON|\n",
      "|2020-11-19|3125.0|3125.0|3125.0|3125.0|3125.0|   3125.0|      AMAZON|\n",
      "|2020-11-18|3140.0|3140.0|3140.0|3140.0|3140.0|   3140.0|      AMAZON|\n",
      "|2020-11-17|3189.0|3189.0|3189.0|3189.0|3189.0|   3189.0|      AMAZON|\n",
      "|2020-11-16|3143.0|3143.0|3143.0|3143.0|3143.0|   3143.0|      AMAZON|\n",
      "|2020-11-13|3142.0|3142.0|3142.0|3142.0|3142.0|   3142.0|      AMAZON|\n",
      "|2020-11-12|3176.0|3176.0|3176.0|3176.0|3176.0|   3176.0|      AMAZON|\n",
      "|2020-11-11|3139.0|3139.0|3139.0|3139.0|3139.0|   3139.0|      AMAZON|\n",
      "|2020-11-10|3114.0|3114.0|3114.0|3114.0|3114.0|   3114.0|      AMAZON|\n",
      "|2020-11-09|3289.0|3289.0|3289.0|3289.0|3289.0|   3289.0|      AMAZON|\n",
      "|2020-11-06|3322.0|3322.0|3322.0|3322.0|3322.0|   3322.0|      AMAZON|\n",
      "|2020-11-05|3367.0|3367.0|3367.0|3367.0|3367.0|   3367.0|      AMAZON|\n",
      "|2020-11-04|3245.0|3245.0|3245.0|3245.0|3245.0|   3245.0|      AMAZON|\n",
      "|2020-11-03|3075.0|3075.0|3075.0|3075.0|3075.0|   3075.0|      AMAZON|\n",
      "|2020-11-02|3080.0|3080.0|3080.0|3080.0|3080.0|   3080.0|      AMAZON|\n",
      "|2020-10-30|3167.0|3167.0|3167.0|3167.0|3167.0|   3167.0|      AMAZON|\n",
      "|2020-10-29|3257.0|3257.0|3257.0|3257.0|3257.0|   3257.0|      AMAZON|\n",
      "|2020-10-28|3264.0|3264.0|3264.0|3264.0|3264.0|   3264.0|      AMAZON|\n",
      "|2020-10-27|3292.0|3292.0|3292.0|3292.0|3292.0|   3292.0|      AMAZON|\n",
      "|2020-10-26|3283.0|3283.0|3283.0|3283.0|3283.0|   3283.0|      AMAZON|\n",
      "|2020-10-23|3205.0|3205.0|3205.0|3205.0|3205.0|   3205.0|      AMAZON|\n",
      "|2020-10-22|3199.0|3199.0|3199.0|3199.0|3199.0|   3199.0|      AMAZON|\n",
      "|2020-10-21|3234.0|3234.0|3234.0|3234.0|3234.0|   3234.0|      AMAZON|\n",
      "|2020-10-20|3266.0|3266.0|3266.0|3266.0|3266.0|   3266.0|      AMAZON|\n",
      "|2020-10-19|3329.0|3329.0|3329.0|3329.0|3329.0|   3329.0|      AMAZON|\n",
      "|2020-10-16|3400.0|3400.0|3400.0|3400.0|3400.0|   3400.0|      AMAZON|\n",
      "|2020-10-15|3356.0|3356.0|3356.0|3356.0|3356.0|   3356.0|      AMAZON|\n",
      "|2020-10-14|3465.0|3465.0|3465.0|3465.0|3465.0|   3465.0|      AMAZON|\n",
      "|2020-10-13|3492.0|3492.0|3492.0|3492.0|3492.0|   3492.0|      AMAZON|\n",
      "|2020-10-12|3496.0|3496.0|3496.0|3496.0|3496.0|   3496.0|      AMAZON|\n",
      "|2020-10-09|3289.0|3289.0|3289.0|3289.0|3289.0|   3289.0|      AMAZON|\n",
      "|2020-10-08|3233.0|3233.0|3233.0|3233.0|3233.0|   3233.0|      AMAZON|\n",
      "|2020-10-07|3200.0|3200.0|3200.0|3200.0|3200.0|   3200.0|      AMAZON|\n",
      "+----------+------+------+------+------+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Missing Data per column:\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'isnan(Date)' due to data type mismatch: argument 1 requires (double or float) type, however, 'Date' is of date type.;\n'Aggregate [count(CASE WHEN (isnan(Date#7310) OR isnull(Date#7310)) THEN Date END) AS Date#7657, count(CASE WHEN (isnan(High#7311) OR isnull(High#7311)) THEN High END) AS High#7659L, count(CASE WHEN (isnan(Low#7312) OR isnull(Low#7312)) THEN Low END) AS Low#7661L, count(CASE WHEN (isnan(Open#7313) OR isnull(Open#7313)) THEN Open END) AS Open#7663L, count(CASE WHEN (isnan(Close#7314) OR isnull(Close#7314)) THEN Close END) AS Close#7665L, count(CASE WHEN (isnan(cast(Volume#7315 as double)) OR isnull(Volume#7315)) THEN Volume END) AS Volume#7667L, count(CASE WHEN (isnan(Adj Close#7316) OR isnull(Adj Close#7316)) THEN Adj Close END) AS Adj Close#7669L, count(CASE WHEN (isnan(cast(company_name#7317 as double)) OR isnull(company_name#7317)) THEN company_name END) AS company_name#7671L]\n+- Relation [Date#7310,High#7311,Low#7312,Open#7313,Close#7314,Volume#7315,Adj Close#7316,company_name#7317] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [44]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mAMZN\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mread_info.__repr__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__repr__\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 13\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_nb_rows()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mprintSchema()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_df_abstract()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshow_missing()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_stats()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mread_info.show_missing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_missing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing Data per column:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mread_info._count_missing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count_missing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misNull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1685\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'isnan(Date)' due to data type mismatch: argument 1 requires (double or float) type, however, 'Date' is of date type.;\n'Aggregate [count(CASE WHEN (isnan(Date#7310) OR isnull(Date#7310)) THEN Date END) AS Date#7657, count(CASE WHEN (isnan(High#7311) OR isnull(High#7311)) THEN High END) AS High#7659L, count(CASE WHEN (isnan(Low#7312) OR isnull(Low#7312)) THEN Low END) AS Low#7661L, count(CASE WHEN (isnan(Open#7313) OR isnull(Open#7313)) THEN Open END) AS Open#7663L, count(CASE WHEN (isnan(Close#7314) OR isnull(Close#7314)) THEN Close END) AS Close#7665L, count(CASE WHEN (isnan(cast(Volume#7315 as double)) OR isnull(Volume#7315)) THEN Volume END) AS Volume#7667L, count(CASE WHEN (isnan(Adj Close#7316) OR isnull(Adj Close#7316)) THEN Adj Close END) AS Adj Close#7669L, count(CASE WHEN (isnan(cast(company_name#7317 as double)) OR isnull(company_name#7317)) THEN company_name END) AS company_name#7671L]\n+- Relation [Date#7310,High#7311,Low#7312,Open#7313,Close#7314,Volume#7315,Adj Close#7316,company_name#7317] csv\n"
     ]
    }
   ],
   "source": [
    "print(AMZN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f70176",
   "metadata": {},
   "outputs": [],
   "source": [
    "##### A FAIRE !!!! UN SCHEMA !!!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "26f23165",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 40 rows:\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|      Date| High|  Low| Open|Close|Volume|Adj Close|company_name|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "|2017-01-03|759.0|759.0|759.0|759.0| 759.0|    759.0|      AMAZON|\n",
      "|2017-01-04|760.0|760.0|760.0|760.0| 760.0|    760.0|      AMAZON|\n",
      "|2017-01-05|782.0|782.0|782.0|782.0| 782.0|    782.0|      AMAZON|\n",
      "|2017-01-06|799.0|799.0|799.0|799.0| 799.0|    799.0|      AMAZON|\n",
      "|2017-01-09|802.0|802.0|802.0|802.0| 802.0|    802.0|      AMAZON|\n",
      "|2017-01-10|798.0|798.0|798.0|798.0| 798.0|    798.0|      AMAZON|\n",
      "|2017-01-11|800.0|800.0|800.0|800.0| 800.0|    800.0|      AMAZON|\n",
      "|2017-01-12|814.0|814.0|814.0|814.0| 814.0|    814.0|      AMAZON|\n",
      "|2017-01-13|822.0|822.0|822.0|822.0| 822.0|    822.0|      AMAZON|\n",
      "|2017-01-17|816.0|816.0|816.0|816.0| 816.0|    816.0|      AMAZON|\n",
      "|2017-01-18|812.0|812.0|812.0|812.0| 812.0|    812.0|      AMAZON|\n",
      "|2017-01-19|814.0|814.0|814.0|814.0| 814.0|    814.0|      AMAZON|\n",
      "|2017-01-20|816.0|816.0|816.0|816.0| 816.0|    816.0|      AMAZON|\n",
      "|2017-01-23|819.0|819.0|819.0|819.0| 819.0|    819.0|      AMAZON|\n",
      "|2017-01-24|824.0|824.0|824.0|824.0| 824.0|    824.0|      AMAZON|\n",
      "|2017-01-25|837.0|837.0|837.0|837.0| 837.0|    837.0|      AMAZON|\n",
      "|2017-01-26|844.0|844.0|844.0|844.0| 844.0|    844.0|      AMAZON|\n",
      "|2017-01-27|840.0|840.0|840.0|840.0| 840.0|    840.0|      AMAZON|\n",
      "|2017-01-30|834.0|834.0|834.0|834.0| 834.0|    834.0|      AMAZON|\n",
      "|2017-01-31|827.0|827.0|827.0|827.0| 827.0|    827.0|      AMAZON|\n",
      "|2017-02-01|834.0|834.0|834.0|834.0| 834.0|    834.0|      AMAZON|\n",
      "|2017-02-02|842.0|842.0|842.0|842.0| 842.0|    842.0|      AMAZON|\n",
      "|2017-02-03|818.0|818.0|818.0|818.0| 818.0|    818.0|      AMAZON|\n",
      "|2017-02-06|811.0|811.0|811.0|811.0| 811.0|    811.0|      AMAZON|\n",
      "|2017-02-07|816.0|816.0|816.0|816.0| 816.0|    816.0|      AMAZON|\n",
      "|2017-02-08|821.0|821.0|821.0|821.0| 821.0|    821.0|      AMAZON|\n",
      "|2017-02-09|825.0|825.0|825.0|825.0| 825.0|    825.0|      AMAZON|\n",
      "|2017-02-10|828.0|828.0|828.0|828.0| 828.0|    828.0|      AMAZON|\n",
      "|2017-02-13|843.0|843.0|843.0|843.0| 843.0|    843.0|      AMAZON|\n",
      "|2017-02-14|838.0|838.0|838.0|838.0| 838.0|    838.0|      AMAZON|\n",
      "|2017-02-15|843.0|843.0|843.0|843.0| 843.0|    843.0|      AMAZON|\n",
      "|2017-02-16|845.0|845.0|845.0|845.0| 845.0|    845.0|      AMAZON|\n",
      "|2017-02-17|847.0|847.0|847.0|847.0| 847.0|    847.0|      AMAZON|\n",
      "|2017-02-21|858.0|858.0|858.0|858.0| 858.0|    858.0|      AMAZON|\n",
      "|2017-02-22|858.0|858.0|858.0|858.0| 858.0|    858.0|      AMAZON|\n",
      "|2017-02-23|861.0|861.0|861.0|861.0| 861.0|    861.0|      AMAZON|\n",
      "|2017-02-24|846.0|846.0|846.0|846.0| 846.0|    846.0|      AMAZON|\n",
      "|2017-02-27|853.0|853.0|853.0|853.0| 853.0|    853.0|      AMAZON|\n",
      "|2017-02-28|854.0|854.0|854.0|854.0| 854.0|    854.0|      AMAZON|\n",
      "|2017-03-01|855.0|855.0|855.0|855.0| 855.0|    855.0|      AMAZON|\n",
      "+----------+-----+-----+-----+-----+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n",
      "Last 40 rows:\n",
      "+----------+------+------+------+------+------+---------+------------+\n",
      "|      Date|  High|   Low|  Open| Close|Volume|Adj Close|company_name|\n",
      "+----------+------+------+------+------+------+---------+------------+\n",
      "|2020-12-02|3224.0|3224.0|3224.0|3224.0|3224.0|   3224.0|      AMAZON|\n",
      "|2020-12-01|3249.0|3249.0|3249.0|3249.0|3249.0|   3249.0|      AMAZON|\n",
      "|2020-11-30|3228.0|3228.0|3228.0|3228.0|3228.0|   3228.0|      AMAZON|\n",
      "|2020-11-27|3216.0|3216.0|3216.0|3216.0|3216.0|   3216.0|      AMAZON|\n",
      "|2020-11-25|3198.0|3198.0|3198.0|3198.0|3198.0|   3198.0|      AMAZON|\n",
      "|2020-11-24|3134.0|3134.0|3134.0|3134.0|3134.0|   3134.0|      AMAZON|\n",
      "|2020-11-23|3140.0|3140.0|3140.0|3140.0|3140.0|   3140.0|      AMAZON|\n",
      "|2020-11-20|3133.0|3133.0|3133.0|3133.0|3133.0|   3133.0|      AMAZON|\n",
      "|2020-11-19|3125.0|3125.0|3125.0|3125.0|3125.0|   3125.0|      AMAZON|\n",
      "|2020-11-18|3140.0|3140.0|3140.0|3140.0|3140.0|   3140.0|      AMAZON|\n",
      "|2020-11-17|3189.0|3189.0|3189.0|3189.0|3189.0|   3189.0|      AMAZON|\n",
      "|2020-11-16|3143.0|3143.0|3143.0|3143.0|3143.0|   3143.0|      AMAZON|\n",
      "|2020-11-13|3142.0|3142.0|3142.0|3142.0|3142.0|   3142.0|      AMAZON|\n",
      "|2020-11-12|3176.0|3176.0|3176.0|3176.0|3176.0|   3176.0|      AMAZON|\n",
      "|2020-11-11|3139.0|3139.0|3139.0|3139.0|3139.0|   3139.0|      AMAZON|\n",
      "|2020-11-10|3114.0|3114.0|3114.0|3114.0|3114.0|   3114.0|      AMAZON|\n",
      "|2020-11-09|3289.0|3289.0|3289.0|3289.0|3289.0|   3289.0|      AMAZON|\n",
      "|2020-11-06|3322.0|3322.0|3322.0|3322.0|3322.0|   3322.0|      AMAZON|\n",
      "|2020-11-05|3367.0|3367.0|3367.0|3367.0|3367.0|   3367.0|      AMAZON|\n",
      "|2020-11-04|3245.0|3245.0|3245.0|3245.0|3245.0|   3245.0|      AMAZON|\n",
      "|2020-11-03|3075.0|3075.0|3075.0|3075.0|3075.0|   3075.0|      AMAZON|\n",
      "|2020-11-02|3080.0|3080.0|3080.0|3080.0|3080.0|   3080.0|      AMAZON|\n",
      "|2020-10-30|3167.0|3167.0|3167.0|3167.0|3167.0|   3167.0|      AMAZON|\n",
      "|2020-10-29|3257.0|3257.0|3257.0|3257.0|3257.0|   3257.0|      AMAZON|\n",
      "|2020-10-28|3264.0|3264.0|3264.0|3264.0|3264.0|   3264.0|      AMAZON|\n",
      "|2020-10-27|3292.0|3292.0|3292.0|3292.0|3292.0|   3292.0|      AMAZON|\n",
      "|2020-10-26|3283.0|3283.0|3283.0|3283.0|3283.0|   3283.0|      AMAZON|\n",
      "|2020-10-23|3205.0|3205.0|3205.0|3205.0|3205.0|   3205.0|      AMAZON|\n",
      "|2020-10-22|3199.0|3199.0|3199.0|3199.0|3199.0|   3199.0|      AMAZON|\n",
      "|2020-10-21|3234.0|3234.0|3234.0|3234.0|3234.0|   3234.0|      AMAZON|\n",
      "|2020-10-20|3266.0|3266.0|3266.0|3266.0|3266.0|   3266.0|      AMAZON|\n",
      "|2020-10-19|3329.0|3329.0|3329.0|3329.0|3329.0|   3329.0|      AMAZON|\n",
      "|2020-10-16|3400.0|3400.0|3400.0|3400.0|3400.0|   3400.0|      AMAZON|\n",
      "|2020-10-15|3356.0|3356.0|3356.0|3356.0|3356.0|   3356.0|      AMAZON|\n",
      "|2020-10-14|3465.0|3465.0|3465.0|3465.0|3465.0|   3465.0|      AMAZON|\n",
      "|2020-10-13|3492.0|3492.0|3492.0|3492.0|3492.0|   3492.0|      AMAZON|\n",
      "|2020-10-12|3496.0|3496.0|3496.0|3496.0|3496.0|   3496.0|      AMAZON|\n",
      "|2020-10-09|3289.0|3289.0|3289.0|3289.0|3289.0|   3289.0|      AMAZON|\n",
      "|2020-10-08|3233.0|3233.0|3233.0|3233.0|3233.0|   3233.0|      AMAZON|\n",
      "|2020-10-07|3200.0|3200.0|3200.0|3200.0|3200.0|   3200.0|      AMAZON|\n",
      "+----------+------+------+------+------+------+---------+------------+\n",
      "only showing top 40 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.get_df_abstract()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82df148b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing Data per column:\n"
     ]
    },
    {
     "ename": "AnalysisException",
     "evalue": "cannot resolve 'isnan(Date)' due to data type mismatch: argument 1 requires (double or float) type, however, 'Date' is of date type.;\n'Aggregate [count(CASE WHEN (isnan(Date#7310) OR isnull(Date#7310)) THEN Date END) AS Date#7673, count(CASE WHEN (isnan(High#7311) OR isnull(High#7311)) THEN High END) AS High#7675L, count(CASE WHEN (isnan(Low#7312) OR isnull(Low#7312)) THEN Low END) AS Low#7677L, count(CASE WHEN (isnan(Open#7313) OR isnull(Open#7313)) THEN Open END) AS Open#7679L, count(CASE WHEN (isnan(Close#7314) OR isnull(Close#7314)) THEN Close END) AS Close#7681L, count(CASE WHEN (isnan(cast(Volume#7315 as double)) OR isnull(Volume#7315)) THEN Volume END) AS Volume#7683L, count(CASE WHEN (isnan(Adj Close#7316) OR isnull(Adj Close#7316)) THEN Adj Close END) AS Adj Close#7685L, count(CASE WHEN (isnan(cast(company_name#7317 as double)) OR isnull(company_name#7317)) THEN company_name END) AS company_name#7687L]\n+- Relation [Date#7310,High#7311,Low#7312,Open#7313,Close#7314,Volume#7315,Adj Close#7316,company_name#7317] csv\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [45]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mread_info.show_missing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_missing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mMissing Data per column:\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 17\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_count_missing\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "Input \u001b[0;32mIn [41]\u001b[0m, in \u001b[0;36mread_info._count_missing\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     86\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_count_missing\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m---> 87\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     88\u001b[0m \u001b[43m        \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m     89\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcount\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwhen\u001b[49m\u001b[43m(\u001b[49m\u001b[43misnan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m|\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43misNull\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43malias\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     90\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mc\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcolumns\u001b[49m\n\u001b[1;32m     91\u001b[0m \u001b[43m        \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     92\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1685\u001b[0m, in \u001b[0;36mDataFrame.select\u001b[0;34m(self, *cols)\u001b[0m\n\u001b[1;32m   1664\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mselect\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mcols):\n\u001b[1;32m   1665\u001b[0m     \u001b[38;5;124;03m\"\"\"Projects a set of expressions and returns a new :class:`DataFrame`.\u001b[39;00m\n\u001b[1;32m   1666\u001b[0m \n\u001b[1;32m   1667\u001b[0m \u001b[38;5;124;03m    .. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1683\u001b[0m \u001b[38;5;124;03m    [Row(name='Alice', age=12), Row(name='Bob', age=15)]\u001b[39;00m\n\u001b[1;32m   1684\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1685\u001b[0m     jdf \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jcols\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mcols\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1686\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(jdf, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: cannot resolve 'isnan(Date)' due to data type mismatch: argument 1 requires (double or float) type, however, 'Date' is of date type.;\n'Aggregate [count(CASE WHEN (isnan(Date#7310) OR isnull(Date#7310)) THEN Date END) AS Date#7673, count(CASE WHEN (isnan(High#7311) OR isnull(High#7311)) THEN High END) AS High#7675L, count(CASE WHEN (isnan(Low#7312) OR isnull(Low#7312)) THEN Low END) AS Low#7677L, count(CASE WHEN (isnan(Open#7313) OR isnull(Open#7313)) THEN Open END) AS Open#7679L, count(CASE WHEN (isnan(Close#7314) OR isnull(Close#7314)) THEN Close END) AS Close#7681L, count(CASE WHEN (isnan(cast(Volume#7315 as double)) OR isnull(Volume#7315)) THEN Volume END) AS Volume#7683L, count(CASE WHEN (isnan(Adj Close#7316) OR isnull(Adj Close#7316)) THEN Adj Close END) AS Adj Close#7685L, count(CASE WHEN (isnan(cast(company_name#7317 as double)) OR isnull(company_name#7317)) THEN company_name END) AS company_name#7687L]\n+- Relation [Date#7310,High#7311,Low#7312,Open#7313,Close#7314,Volume#7315,Adj Close#7316,company_name#7317] csv\n"
     ]
    }
   ],
   "source": [
    "AMZN.show_missing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "15255774",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------+\n",
      "|summary|              High|               Low|             Open|             Close|           Volume|         Adj Close|company_name|\n",
      "+-------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------+\n",
      "|  count|               987|               987|              987|               987|              987|               987|         987|\n",
      "|   mean|1762.0071216958152|1722.1011452099956|1743.433881363487|1742.9566644206718| 4509728.05775076|1742.9566644206718|        null|\n",
      "| stddev| 667.2385315752688| 644.7988093382758|657.1153070927137| 655.9576061129322|2179817.628631287| 655.9576061129322|        null|\n",
      "|    min|  758.760009765625| 747.7000122070312|757.9199829101562| 753.6699829101562|           881300| 753.6699829101562|      AMAZON|\n",
      "|    25%|            1191.0|            1176.0|1188.300048828125|1186.0999755859375|          2982700|1186.0999755859375|        null|\n",
      "|    50%|   1756.9599609375|  1719.22998046875|1742.239990234375|1739.6500244140625|          3925600|1739.6500244140625|        null|\n",
      "|    75%|1941.5899658203125|1900.3399658203125| 1922.97998046875|  1918.18994140625|          5429100|  1918.18994140625|        null|\n",
      "|    max|           3552.25|  3486.68994140625|           3547.0| 3531.449951171875|         16565000| 3531.449951171875|      AMAZON|\n",
      "+-------+------------------+------------------+-----------------+------------------+-----------------+------------------+------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN._get_stats()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4a01b862",
   "metadata": {},
   "outputs": [
    {
     "ename": "AnalysisException",
     "evalue": "Can't extract value from date#0: need struct type but got date",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAnalysisException\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [11]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtest\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m              \u001b[49m\u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdatediff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mdate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mshow()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:2478\u001b[0m, in \u001b[0;36mDataFrame.withColumn\u001b[0;34m(self, colName, col)\u001b[0m\n\u001b[1;32m   2476\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(col, Column):\n\u001b[1;32m   2477\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcol should be Column\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m-> 2478\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrame(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mwithColumn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolName\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcol\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_jc\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msql_ctx)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/py4j/java_gateway.py:1321\u001b[0m, in \u001b[0;36mJavaMember.__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1315\u001b[0m command \u001b[38;5;241m=\u001b[39m proto\u001b[38;5;241m.\u001b[39mCALL_COMMAND_NAME \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1316\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommand_header \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1317\u001b[0m     args_command \u001b[38;5;241m+\u001b[39m\\\n\u001b[1;32m   1318\u001b[0m     proto\u001b[38;5;241m.\u001b[39mEND_COMMAND_PART\n\u001b[1;32m   1320\u001b[0m answer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mgateway_client\u001b[38;5;241m.\u001b[39msend_command(command)\n\u001b[0;32m-> 1321\u001b[0m return_value \u001b[38;5;241m=\u001b[39m \u001b[43mget_return_value\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1322\u001b[0m \u001b[43m    \u001b[49m\u001b[43manswer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgateway_client\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtarget_id\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1324\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m temp_arg \u001b[38;5;129;01min\u001b[39;00m temp_args:\n\u001b[1;32m   1325\u001b[0m     temp_arg\u001b[38;5;241m.\u001b[39m_detach()\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/utils.py:117\u001b[0m, in \u001b[0;36mcapture_sql_exception.<locals>.deco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    113\u001b[0m converted \u001b[38;5;241m=\u001b[39m convert_exception(e\u001b[38;5;241m.\u001b[39mjava_exception)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(converted, UnknownException):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;66;03m# Hide where the exception came from that shows a non-Pythonic\u001b[39;00m\n\u001b[1;32m    116\u001b[0m     \u001b[38;5;66;03m# JVM exception message.\u001b[39;00m\n\u001b[0;32m--> 117\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m converted \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    118\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    119\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[0;31mAnalysisException\u001b[0m: Can't extract value from date#0: need struct type but got date"
     ]
    }
   ],
   "source": [
    "AMZN.df.withColumn(\"test\", \n",
    "              func.datediff(AMZN.df[\"date\"][0], AMZN.df[\"date\"][1])).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "365d1e63",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Date[2]'>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df[\"Date\"].getItem(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "eddb895b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.date(2017, 1, 3)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df.first()['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb3a22d0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute '__get_item'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [14]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__get_item\u001b[49m(\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute '__get_item'"
     ]
    }
   ],
   "source": [
    "AMZN.df.__get_item(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f028cf0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'DataFrame' object has no attribute 'second'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [15]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msecond\u001b[49m()[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m'\u001b[39m]\n",
      "File \u001b[0;32m/usr/local/lib/python3.9/site-packages/pyspark/sql/dataframe.py:1659\u001b[0m, in \u001b[0;36mDataFrame.__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1649\u001b[0m \u001b[38;5;124;03m\"\"\"Returns the :class:`Column` denoted by ``name``.\u001b[39;00m\n\u001b[1;32m   1650\u001b[0m \n\u001b[1;32m   1651\u001b[0m \u001b[38;5;124;03m.. versionadded:: 1.3.0\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1656\u001b[0m \u001b[38;5;124;03m[Row(age=2), Row(age=5)]\u001b[39;00m\n\u001b[1;32m   1657\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1658\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m name \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns:\n\u001b[0;32m-> 1659\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAttributeError\u001b[39;00m(\n\u001b[1;32m   1660\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m object has no attribute \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, name))\n\u001b[1;32m   1661\u001b[0m jc \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jdf\u001b[38;5;241m.\u001b[39mapply(name)\n\u001b[1;32m   1662\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m Column(jc)\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'DataFrame' object has no attribute 'second'"
     ]
    }
   ],
   "source": [
    "AMZN.df.second()['Date']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a3dd66b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'pyspark.sql.functions' has no attribute 'getrows'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetrows\u001b[49m(AMZN\u001b[38;5;241m.\u001b[39mdf, rownums\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m2\u001b[39m])\u001b[38;5;241m.\u001b[39mcollect()\n",
      "\u001b[0;31mAttributeError\u001b[0m: module 'pyspark.sql.functions' has no attribute 'getrows'"
     ]
    }
   ],
   "source": [
    "func.getrows(AMZN.df, rownums=[0, 2]).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "57e3a420",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "'Column' object is not callable",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [18]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__getitem__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfirst\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mTypeError\u001b[0m: 'Column' object is not callable"
     ]
    }
   ],
   "source": [
    "AMZN.df[0].__getitem__(\"Date\").first()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b448aef2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Column<'Date'>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5701f48",
   "metadata": {},
   "outputs": [],
   "source": [
    "AMZN.df.select('Date').show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0d0d6638",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Date: date, High: double, Low: double, Open: double, Close: double, Volume: int, Adj Close: double, company_name: string]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1c0df1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext\n",
    "from pyspark.sql import SQLContext\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "\n",
    "\n",
    "my_window = Window.partitionBy().orderBy(\"Date\")\n",
    "\n",
    "df = AMZN.df.withColumn(\"prev_value\", F.lag(AMZN.df.Date).over(my_window))\n",
    "df = df.withColumn(\"diff\", F.when(F.isnull(F.datediff(df.Date, df.prev_value)), 0)\n",
    "                              .otherwise(F.datediff(df.Date, df.prev_value)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "562e3d45",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/20 08:12:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/20 08:12:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/20 08:12:18 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+\n",
      "|diff|\n",
      "+----+\n",
      "|   0|\n",
      "|   1|\n",
      "|   1|\n",
      "|   1|\n",
      "|   3|\n",
      "|   1|\n",
      "|   1|\n",
      "|   1|\n",
      "|   1|\n",
      "|   4|\n",
      "|   1|\n",
      "|   1|\n",
      "|   1|\n",
      "|   3|\n",
      "|   1|\n",
      "|   1|\n",
      "|   1|\n",
      "|   1|\n",
      "|   3|\n",
      "|   1|\n",
      "+----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"diff\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "3fc0cfc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql.functions import mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "99353f6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/05/20 08:12:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n",
      "22/05/20 08:12:22 WARN WindowExec: No Partition Defined for Window operation! Moving all data to a single partition, this can cause serious performance degradation.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.447821681864235"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.select(mean('diff')).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e1854374",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.999196080434689"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df.stat.corr('High', 'Low')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "281c465e",
   "metadata": {},
   "source": [
    "TODO: Create function to compute per month week year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b0550d48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742.9566644206718"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AMZN.df.select(mean (\"Close\")).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "644296bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_col_mean(df, col):\n",
    "    return df.select(mean (col)).first()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "ec177261",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1742.9566644206718"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_col_mean(AMZN.df, \"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9fbcbc19",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [30]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m AMZN\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mgroupBy(func\u001b[38;5;241m.\u001b[39mweekofyear(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_by_week\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "AMZN.df.groupBy(func.weekofyear(\"day\").alias(\"date_by_week\")).agg(sum(\"Date\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "b945aeb5",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [31]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m AMZN\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mgroupBy(func\u001b[38;5;241m.\u001b[39mweekofyear(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mday\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_by_week\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m)\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdate_by_week\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "AMZN.df.groupBy(func.weekofyear(\"day\").alias(\"date_by_week\")).agg(sum(\"Close\")).orderBy(\"date_by_week\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "53c3f88f",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unsupported operand type(s) for +: 'int' and 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [32]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m AMZN\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39mwithColumn(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m,func\u001b[38;5;241m.\u001b[39mdate_sub(func\u001b[38;5;241m.\u001b[39mnext_day(col(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m),\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msunday\u001b[39m\u001b[38;5;124m\"\u001b[39m),\u001b[38;5;241m7\u001b[39m))\u001b[38;5;241m.\u001b[39mgroupBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDate\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39magg(\u001b[38;5;28;43msum\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mClose\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39malias(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose_total\u001b[39m\u001b[38;5;124m\"\u001b[39m))\u001b[38;5;241m.\u001b[39morderBy(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mweek_strt_day\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mTypeError\u001b[0m: unsupported operand type(s) for +: 'int' and 'str'"
     ]
    }
   ],
   "source": [
    "AMZN.df.withColumn(\"Date\",func.date_sub(func.next_day(col(\"Date\"),\"sunday\"),7)).groupBy(\"Date\").agg(sum(\"Close\").cast(\"int\").alias(\"Close_total\")).orderBy(\"week_strt_day\").show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6af616d8",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'GroupedData' object has no attribute 'select'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [33]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mAMZN\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgroupBy\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDate\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mClose\u001b[39m\u001b[38;5;124m\"\u001b[39m)\u001b[38;5;241m.\u001b[39mshow()\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'GroupedData' object has no attribute 'select'"
     ]
    }
   ],
   "source": [
    "AMZN.df.groupBy(\"Date\").select(\"Close\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b666c997",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|hour|        close_mean|\n",
      "+----+------------------+\n",
      "|  12| 1563.564484627016|\n",
      "|   1|1417.4578305899379|\n",
      "|   6|1788.4167071174172|\n",
      "|   3|1486.8781597970546|\n",
      "|   5|1689.0211671341297|\n",
      "|   9|1988.6682525634765|\n",
      "|   4| 1634.024632151534|\n",
      "|   8|1951.5419085213307|\n",
      "|   7|1977.4292940027574|\n",
      "|  10| 1937.555771891276|\n",
      "|  11|1907.2337825123857|\n",
      "|   2|1492.8052617123253|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.df.groupBy(func.month(\"Date\").alias(\"hour\")).agg(mean(\"Close\").alias(\"close_mean\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ad11668e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+----+------------------+\n",
      "|hour|        close_mean|\n",
      "+----+------------------+\n",
      "|2018|1641.7261758629545|\n",
      "|2019| 1789.189206077939|\n",
      "|2020| 2636.649604240712|\n",
      "|2017| 968.1670116409363|\n",
      "+----+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "AMZN.df.groupBy(func.year(\"Date\").alias(\"hour\")).agg(mean(\"Close\").alias(\"close_mean\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8c9d82f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1ce0fdd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|new_time|        Close_mean|\n",
      "+--------+------------------+\n",
      "|    2018|1641.7261758629545|\n",
      "|    2019| 1789.189206077939|\n",
      "|    2020| 2636.649604240712|\n",
      "|    2017| 968.1670116409363|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_avg(AMZN.df, \"Close\", func.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c4dc6f69",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------+------------------+\n",
      "|new_time|         Open_mean|\n",
      "+--------+------------------+\n",
      "|    2018|1644.0727091633466|\n",
      "|    2019|1788.7461896623884|\n",
      "|    2020|2636.5054538710433|\n",
      "|    2017|  968.275618959708|\n",
      "+--------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_avg(AMZN.df, \"Open\", func.year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "4300b1cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Exploration(object):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "\n",
    "    def get_oc_avg(self, fun):\n",
    "        close = self._compute_avg(self.df, \"Close\", fun)\n",
    "        opening = self._compute_avg(self.df, \"Open\", fun)\n",
    "\n",
    "        return close.join(\n",
    "            opening, opening.Open_new_time == close.Close_new_time, \"inner\"\n",
    "        ).orderBy(\"Close_new_time\").select(\n",
    "            close.Close_new_time, close.Close_mean, opening.Open_mean\n",
    "        )\n",
    "\n",
    "    def _compute_avg(self, df, col, fun):\n",
    "        return df.groupBy(fun(\"Date\").alias(col + \"_new_time\")).agg(\n",
    "            mean(col).alias(col + \"_mean\")\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "5416144c",
   "metadata": {},
   "outputs": [],
   "source": [
    "exAMZN = Exploration(AMZN.df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "f6080b6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|\n",
      "+--------------+------------------+------------------+\n",
      "|             1|1417.4578305899379|1413.4312052899097|\n",
      "|             2|1492.8052617123253|1493.1706575092517|\n",
      "|             3|1486.8781597970546|1484.0394181876347|\n",
      "|             4| 1634.024632151534|1632.4401230230565|\n",
      "|             5|1689.0211671341297|1687.3904660247092|\n",
      "|             6|1788.4167071174172|1788.4576480641085|\n",
      "|             7|1977.4292940027574|1977.4004746380974|\n",
      "|             8|1951.5419085213307|1950.0660695279582|\n",
      "|             9|1988.6682525634765| 1996.003623199463|\n",
      "|            10| 1937.555771891276| 1943.571671549479|\n",
      "|            11|1907.2337825123857|1907.4091514029153|\n",
      "|            12| 1563.564484627016|1568.1172583795362|\n",
      "+--------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exAMZN.get_oc_avg(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "62bea182",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|\n",
      "+--------------+------------------+------------------+\n",
      "|          2017| 968.1670116409363|  968.275618959708|\n",
      "|          2018|1641.7261758629545|1644.0727091633466|\n",
      "|          2019| 1789.189206077939|1788.7461896623884|\n",
      "|          2020| 2636.649604240712|2636.5054538710433|\n",
      "+--------------+------------------+------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "exAMZN.get_oc_avg(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "719891a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_price_change(period=None):\n",
    "    df = AMZN.df\n",
    "    if period:\n",
    "        df= exAMZN.get_oc_avg(period)\n",
    "   \n",
    "    return  df.withColumn('diff', ( df['Close_mean'] - df['Open_mean'] ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "9af25cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+--------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|                diff|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "|             1|1417.4578305899379|1413.4312052899097|   4.026625300028172|\n",
      "|             2|1492.8052617123253|1493.1706575092517|-0.36539579692635016|\n",
      "|             3|1486.8781597970546|1484.0394181876347|  2.8387416094199125|\n",
      "|             4| 1634.024632151534|1632.4401230230565|  1.5845091284775208|\n",
      "|             5|1689.0211671341297|1687.3904660247092|  1.6307011094204427|\n",
      "|             6|1788.4167071174172|1788.4576480641085|-0.04094094669130...|\n",
      "|             7|1977.4292940027574|1977.4004746380974|0.028819364659966595|\n",
      "|             8|1951.5419085213307|1950.0660695279582|   1.475838993372463|\n",
      "|             9|1988.6682525634765| 1996.003623199463| -7.3353706359864645|\n",
      "|            10| 1937.555771891276| 1943.571671549479|  -6.015899658203125|\n",
      "|            11|1907.2337825123857|1907.4091514029153| -0.1753688905296258|\n",
      "|            12| 1563.564484627016|1568.1172583795362|  -4.552773752520125|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_price_change(func.month).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "ce58d903",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+------------------+------------------+--------------------+\n",
      "|Close_new_time|        Close_mean|         Open_mean|                diff|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "|          2017| 968.1670116409363|  968.275618959708|-0.10860731877176022|\n",
      "|          2018|1641.7261758629545|1644.0727091633466| -2.3465333003921387|\n",
      "|          2019| 1789.189206077939|1788.7461896623884|  0.4430164155505736|\n",
      "|          2020| 2636.649604240712|2636.5054538710433|  0.1441503696687505|\n",
      "+--------------+------------------+------------------+--------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "get_price_change(func.year).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aadcf9c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "nbTranslate": {
   "displayLangs": [
    "*"
   ],
   "hotkey": "alt-t",
   "langInMainMenu": true,
   "sourceLang": "en",
   "targetLang": "fr",
   "useGoogleTranslate": true
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
